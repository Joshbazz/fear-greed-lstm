{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome! All code included in the Python Implementation is also included here for ease of use. You can run this entire notebook from start to finish, and look at generated console outputs, and visualizations generated as saved PNGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below gathers Fear and Index Data, and combines it with Bitcoin price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "def fetch_fear_and_greed_btc():\n",
    "    # Define the API endpoint and parameters for Fear and Greed Index\n",
    "    fng_api_url = \"https://api.alternative.me/fng/\"\n",
    "    fng_params = {\n",
    "        'limit': 0,  # Get all available data\n",
    "        'format': 'json'\n",
    "    }\n",
    "\n",
    "    # Make the GET request to the Fear and Greed Index API\n",
    "    response = requests.get(fng_api_url, params=fng_params)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        fng_data = response.json()\n",
    "        # Convert the data to a Pandas DataFrame\n",
    "        fng_df = pd.DataFrame(fng_data['data'])\n",
    "        # Ensure the timestamp column is of numeric type before converting to datetime\n",
    "        fng_df['timestamp'] = pd.to_numeric(fng_df['timestamp'], errors='coerce')\n",
    "        # Convert the timestamp column to datetime\n",
    "        fng_df['timestamp'] = pd.to_datetime(fng_df['timestamp'], unit='s')\n",
    "        # Drop the time_until_update column\n",
    "        fng_df.drop(columns=['time_until_update'], inplace=True)\n",
    "        # Set the timestamp as the index\n",
    "        fng_df.set_index('timestamp', inplace=True)\n",
    "        # Sort the DataFrame by the index (timestamp) in ascending order\n",
    "        fng_df.sort_index(inplace=True)\n",
    "        # Save the Fear and Greed Index DataFrame to a CSV file with timestamp as index and column name 'timestamp'\n",
    "        fng_df.to_csv('fear_and_greed_index.csv', index=True, index_label='timestamp')\n",
    "        print(\"Fear and Greed Index data has been saved to 'fear_and_greed_index.csv'.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch Fear and Greed Index data. Status code: {response.status_code}\")\n",
    "\n",
    "    # Fetch daily Bitcoin prices using Yahoo Finance\n",
    "    btc_data = yf.download('BTC-USD', start=fng_df.index.min().strftime('%Y-%m-%d'), end=fng_df.index.max().strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Concatenate Fear and Greed Index DataFrame with Bitcoin DataFrame based on date index\n",
    "    combined_df = pd.concat([fng_df, btc_data], axis=1, join='inner')\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    combined_df.to_csv('fear_greed_btc_combined.csv', index=True, index_label='timestamp')\n",
    "    print(\"Combined data has been saved to 'fear_greed_btc_combined.csv'.\")\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below contains a DataPreprocessor Class for getting data ready for use by our LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, X_scaler=RobustScaler(), y_scaler=RobustScaler(), lag_features=['value', 'Close'], lags=5, target_col='Close', test_size=.25, window_size=5):\n",
    "        self.lag_features = lag_features\n",
    "        self.lags = lags\n",
    "        self.window_size = window_size\n",
    "        self.target_col = target_col\n",
    "        self.test_size = test_size\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "    def create_lagged_features(self, df):\n",
    "        for feature in self.lag_features:\n",
    "            for lag in range(1, self.lags + 1):\n",
    "                df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "        df['target'] = df[self.target_col]\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def convert_to_window_format(self, df):\n",
    "        X, y, dates = [], [], []\n",
    "        for i in range(len(df) - self.window_size):\n",
    "            window = df.iloc[i:i+self.window_size]\n",
    "            X.append(window.drop(columns=['target', 'Close', 'Adj Close']).values)\n",
    "            # Append the Close price of the last day in the window as the target\n",
    "            y.append(window.iloc[-1]['Close'])\n",
    "            dates.append(window.index[-1]) # store the date of the last row in the window\n",
    "        self.X, self.y = np.array(X), np.array(y)\n",
    "        self.dates = np.array(dates)\n",
    "\n",
    "        return self.X, self.y, self.dates\n",
    "\n",
    "    def normalize_data(self, X_train, X_test, y_train, y_test):\n",
    "        # Reshape X_train and X_test to fit_transform\n",
    "        X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "        X_test_reshaped = X_test.reshape(-1, X_test.shape[-1])\n",
    "\n",
    "        X_train_scaled = self.X_scaler.fit_transform(X_train_reshaped)\n",
    "        X_test_scaled = self.X_scaler.transform(X_test_reshaped)\n",
    "        \n",
    "        # Reshape back to original shape\n",
    "        X_train_scaled = X_train_scaled.reshape(X_train.shape)\n",
    "        X_test_scaled = X_test_scaled.reshape(X_test.shape)\n",
    "\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        y_train_scaled = self.y_scaler.fit_transform(y_train)\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "        y_test_scaled = self.y_scaler.transform(y_test)\n",
    "\n",
    "        return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled\n",
    "\n",
    "    def split_train_test(self, data):\n",
    "        lagged_df = self.create_lagged_features(data)\n",
    "        lagged_df = lagged_df.drop(columns=['value_classification'])\n",
    "\n",
    "        self.X, self.y, self.dates = self.convert_to_window_format(lagged_df)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=self.test_size, shuffle=False)\n",
    "\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.normalize_data(\n",
    "            X_train, X_test, y_train, y_test\n",
    "        )\n",
    "        self.dates_train = self.dates[:len(y_train_scaled)]\n",
    "        self.dates_test = self.dates[len(y_train_scaled):]\n",
    "        self.features_test_df = lagged_df[-len(self.dates_test)-1:] #NOTE this could cause issues\n",
    "\n",
    "        return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_test, y_test, self.dates_train, self.dates_test, self.features_test_df\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        return self.split_train_test(data)\n",
    "\n",
    "    def inverse_transform_y(self, y_scaled):\n",
    "        return self.y_scaler.inverse_transform(y_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the Signal Generation function. Update the code here to implement a new strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# from keras.models import load_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import datetime\n",
    "\n",
    "\n",
    "def generate_signal(test_features, predictions, dates_test, model_path=None):\n",
    "\n",
    "    # put your predictions vector back into the test features dataframe\n",
    "    dates_test_reshaped = dates_test.reshape(-1, 1)\n",
    "\n",
    "    combined_array = np.concatenate((dates_test_reshaped, predictions), axis=1)\n",
    "    # print(combined_array[:10])\n",
    "\n",
    "    df_combined = pd.DataFrame(combined_array, columns=['Date', 'Predicted_Close'])\n",
    "    df_combined.set_index('Date', inplace=True)\n",
    "\n",
    "    result_df = pd.concat([test_features, df_combined], axis=1)\n",
    "\n",
    "####################################################################################\n",
    "#------------------------CREATE YOUR STRATEGY HERE---------------------------------#\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "    # Initialize an empty list to store signals\n",
    "    signals = []\n",
    "\n",
    "    # Iterate through each row of the DataFrame\n",
    "    for i in range(len(result_df) - 1):\n",
    "        open = result_df['Open'].iloc[i]\n",
    "        prediction = result_df['Predicted_Close'].iloc[i]\n",
    "        \n",
    "        # Define your buy and sell conditions here (modular and editable)\n",
    "        if open < prediction:\n",
    "            signal = 1  # Buy signal\n",
    "        else:\n",
    "            signal = -1  # Sell signal\n",
    "        \n",
    "        signals.append(signal)\n",
    "\n",
    "    # Handle the last element if necessary\n",
    "    if len(signals) < len(test_features):\n",
    "        signals.append(None)\n",
    "\n",
    "    # Add the signals list as a new column 'signal' in the DataFrame\n",
    "    test_features['Signal'] = signals\n",
    "\n",
    "    # Get the current timestamp and format it\n",
    "    current_timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    # Define the full path for the new CSV file\n",
    "    csv_path = os.path.join(f'{current_timestamp}_new_data_with_positions.csv')\n",
    "\n",
    "    # Save new_data with positions\n",
    "    test_features.to_csv(csv_path, index=True)\n",
    "\n",
    "    return test_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the ModelEvaluator Class, used for evaluating our model's predictive capabilities on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_signals import generate_signal\n",
    "from plotting_utils import plot_predicted_actual, plot_residuals\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model, X_test, y_test, X_test_scaled, y_test_scaled, y_scaler, model_path=None):\n",
    "        self.model = model\n",
    "        self.model_path = model_path\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.X_test_scaled = X_test_scaled\n",
    "        self.y_test_scaled = y_test_scaled\n",
    "        self.y_scaler = y_scaler\n",
    "        self.predictions = None\n",
    "        self.predictions_inversed = None\n",
    "        self.y_test_inversed = None\n",
    "\n",
    "        if not self.model and model_path:\n",
    "            self.load_saved_model(model_path)    \n",
    "    \n",
    "    def load_saved_model(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "        print(f'Model loaded from {model_path}')\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        loss, mae = self.model.evaluate(self.X_test_scaled, self.y_test_scaled, verbose=2)\n",
    "        error_in_dollars = self.y_test.mean() * mae\n",
    "        print(f'Test Loss: {loss:.4f}')\n",
    "        print(f'Test MAE: {mae:.2f}')\n",
    "        print(f'MAE in dollars: +/- ${error_in_dollars:.2f}')\n",
    "\n",
    "    def atr_to_data(self, window=30):\n",
    "        self.X_test['ATR'] = self.calculate_atr()\n",
    "        atr_total_test = self.X_test['ATR'].mean()\n",
    "        atr_last_window = self.X_test['ATR'].iloc[-window:].mean()\n",
    "        print(f\"ATR for all test observations: ${atr_total_test:.2f}\")\n",
    "        print(f\"ATR for last {window} observations: ${atr_last_window:.2f}\")\n",
    "\n",
    "    def calculate_atr(self, window=14):\n",
    "        high_low = self.X_test['High'] - self.X_test['Low']\n",
    "        high_close_prev = abs(self.X_test['High'] - self.X_test['Close'].shift(1))\n",
    "        low_close_prev = abs(self.X_test['Low'] - self.X_test['Close'].shift(1))\n",
    "\n",
    "        tr = high_low.to_frame(name='HL')\n",
    "        tr['HC_prev'] = high_close_prev\n",
    "        tr['LC_prev'] = low_close_prev\n",
    "\n",
    "        true_range = tr.max(axis=1)\n",
    "\n",
    "        atr = true_range.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "        return atr\n",
    "        \n",
    "    def predict_model(self):\n",
    "        self.predictions = self.model.predict(self.X_test_scaled)\n",
    "        self.predictions_inversed = self.y_scaler.inverse_transform(self.predictions)\n",
    "        self.y_test_inversed = self.y_scaler.inverse_transform(self.y_test_scaled)\n",
    "        plot_predicted_actual(self.y_test_inversed, self.predictions_inversed)\n",
    "        plot_residuals(self.y_test_inversed, self.predictions_inversed)\n",
    "\n",
    "        return self.predictions_inversed\n",
    "\n",
    "    def generate_model_signals(self):\n",
    "        self.X_test = generate_signal(self.X_test_scaled, self.predictions_inversed)\n",
    "        print(self.X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the functions for generating the visualizations we will see when our LSTMModel trains and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def plot_loss_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    save_plot(\"loss_training_history\")\n",
    "\n",
    "def plot_mae_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "    plt.title('Model MAE Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    save_plot(\"MAE_training_history\")\n",
    "\n",
    "def plot_predicted_actual(actual, predicted):\n",
    "    # Flatten the 2D arrays to 1D\n",
    "    actual = np.ravel(actual)\n",
    "    predicted = np.ravel(predicted)\n",
    "\n",
    "    df = pd.DataFrame({'Actual': actual, 'Predicted': predicted})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='Actual', y='Predicted', data=df)\n",
    "    plt.plot([min(actual), max(actual)], [min(actual), max(actual)], color='red', linestyle='--')\n",
    "    plt.title('Predicted vs. Actual Values')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.grid(True)\n",
    "    save_plot(\"Predicted_vs_Actual\")\n",
    "\n",
    "def plot_residuals(actual, predicted):\n",
    "    # Flatten the 2D arrays to 1D\n",
    "    actual = np.ravel(actual)\n",
    "    predicted = np.ravel(predicted)\n",
    "    residuals = actual - predicted\n",
    "\n",
    "    # residuals = [actual - predicted for actual, predicted in zip(actual, predicted)]\n",
    "    df = pd.DataFrame({'Actual': actual, 'Predicted': predicted, 'Residuals': residuals})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='Predicted', y='Residuals', data=df)\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.title('Residuals Plot')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.grid(True)\n",
    "    save_plot(\"Residuals\")\n",
    "\n",
    "def save_and_visualize_model(model, img_dir=None):\n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    if img_dir is None:\n",
    "        img_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    img_path = os.path.join(img_dir, f\"model_{timestamp}.png\")\n",
    "    plot_model(\n",
    "        model,\n",
    "        to_file=img_path,\n",
    "        show_shapes=True,\n",
    "        show_dtype=False,\n",
    "        show_layer_names=True,\n",
    "        rankdir=\"TB\",\n",
    "        expand_nested=False,\n",
    "        dpi=200,\n",
    "        show_layer_activations=True,\n",
    "        show_trainable=True\n",
    "    )\n",
    "    print(f\"Model visualization saved and displayed from {img_path}\")\n",
    "    # save_plot(\"Model_Arc\")\n",
    "\n",
    "def plot_PCA(X_scaled):\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)  # Reduce to 2 dimensions\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Plot PCA results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "    plt.title('PCA Visualization')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.grid(True)\n",
    "    # plt.show()\n",
    "\n",
    "    save_plot(\"PCA_graph\")\n",
    "\n",
    "\n",
    "def save_plot(plot_name):\n",
    "    current_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    plt.savefig(f'{plot_name}_{current_timestamp}.png')\n",
    "    plt.close()\n",
    "    print(f\"{plot_name} plot saved as '{plot_name}_{current_timestamp}.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the Backtesting code so we can test the efficacy of our predictions and strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from backtesting import Backtest, Strategy\n",
    "    \n",
    "class SignalStrategy(Strategy):\n",
    "    def init(self):\n",
    "        self.signal = self.data.Signal\n",
    "\n",
    "    def next(self):\n",
    "        current_signal = self.data.Signal[-1]\n",
    "        current_date = self.data.index[-1]\n",
    "        # print(f\"Date: {current_date}, Current position size: {self.position.size}, Signal: {current_signal}, Position: {self.position.is_long}\")\n",
    "        \n",
    "        if current_signal == 1:\n",
    "            # print(\"Executing BUY order\")\n",
    "            self.buy(size=1)\n",
    "        elif current_signal == -1 and self.position.is_long:\n",
    "            # print(\"Attempting to SELL entire position\")\n",
    "            try:\n",
    "                self.position.close()  # This closes the entire position\n",
    "                # print(\"SELL order executed - entire position closed\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing SELL order: {e}\")\n",
    "        elif current_signal == 0:\n",
    "            # print(\"No trade executed\")\n",
    "            pass\n",
    "    \n",
    "        \n",
    "        # print(f\"Current position size: {self.position.size}\")\n",
    "\n",
    "\n",
    "def run_backtest(data_path=None, data=None, plot=True, cash=1_000_000, commission=0.002, trade_on_close=True):\n",
    "    if data_path:\n",
    "        # Load and preprocess the data from the specified path\n",
    "        dataframe = pd.read_csv(data_path, index_col='Date', parse_dates=True)\n",
    "        dataframe = dataframe.sort_index()\n",
    "        dataframe = dataframe.dropna()\n",
    "        dataframe = dataframe.drop_duplicates()\n",
    "        dataframe.columns = [column.capitalize() for column in dataframe.columns]\n",
    "    elif data is not None:\n",
    "        # Use self.data if called from LSTMModel instance\n",
    "        dataframe = data  # Assuming `self.data` is defined in LSTMModel\n",
    "    \n",
    "    # Initialize and run the backtest\n",
    "    bt = Backtest(dataframe, SignalStrategy, cash=cash, commission=commission, trade_on_close=trade_on_close)\n",
    "    stats = bt.run()\n",
    "\n",
    "    # Print the statistics and plot the backtest results\n",
    "    print(stats)\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    stats_output_file = f'backtest_stats_{current_time}.txt'\n",
    "\n",
    "    # Save the statistics to a text file if stats_output_file is provided\n",
    "    with open(stats_output_file, 'w') as f:\n",
    "        f.write(str(stats))\n",
    "\n",
    "    if plot == True:\n",
    "        bt.plot()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main Brain of the code, the LSTMModel Class. This is where your entire model will use all the modules above to create, train and test an LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data path preloaded. Downloading Fear and Greed and BTC data...\n",
      "Fear and Greed Index data has been saved to 'fear_and_greed_index.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data has been saved to 'fear_greed_btc_combined.csv'.\n",
      "(1756, 5, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">517</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,102,244</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">517</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m517\u001b[0m)            │     \u001b[38;5;34m1,102,244\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m517\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │        \u001b[38;5;34m18,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120,929</span> (4.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,120,929\u001b[0m (4.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120,929</span> (4.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,120,929\u001b[0m (4.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Model visualization saved and displayed from /Users/joshbazz/Desktop/Bootcamp/fear-greed-lstm/model_2024_07_14_16_48_22.png\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.2095 - mean_absolute_error: 0.2456 - val_loss: 0.0112 - val_mean_absolute_error: 0.0852\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0160 - mean_absolute_error: 0.0845 - val_loss: 0.0129 - val_mean_absolute_error: 0.0945\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0117 - mean_absolute_error: 0.0709 - val_loss: 0.0111 - val_mean_absolute_error: 0.0760\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0072 - mean_absolute_error: 0.0555 - val_loss: 0.0053 - val_mean_absolute_error: 0.0535\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0063 - mean_absolute_error: 0.0518 - val_loss: 0.0062 - val_mean_absolute_error: 0.0556\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - mean_absolute_error: 0.0492 - val_loss: 0.0046 - val_mean_absolute_error: 0.0486\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mean_absolute_error: 0.0459 - val_loss: 0.0045 - val_mean_absolute_error: 0.0479\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0046 - mean_absolute_error: 0.0437 - val_loss: 0.0044 - val_mean_absolute_error: 0.0473\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mean_absolute_error: 0.0432 - val_loss: 0.0047 - val_mean_absolute_error: 0.0487\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0052 - mean_absolute_error: 0.0466 - val_loss: 0.0044 - val_mean_absolute_error: 0.0485\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0042 - mean_absolute_error: 0.0409 - val_loss: 0.0046 - val_mean_absolute_error: 0.0487\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0041 - mean_absolute_error: 0.0406 - val_loss: 0.0049 - val_mean_absolute_error: 0.0496\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0036 - mean_absolute_error: 0.0380 - val_loss: 0.0045 - val_mean_absolute_error: 0.0475\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0041 - mean_absolute_error: 0.0399 - val_loss: 0.0046 - val_mean_absolute_error: 0.0480\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0041 - mean_absolute_error: 0.0396 - val_loss: 0.0051 - val_mean_absolute_error: 0.0501\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0042 - mean_absolute_error: 0.0403 - val_loss: 0.0042 - val_mean_absolute_error: 0.0481\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0035 - mean_absolute_error: 0.0375 - val_loss: 0.0040 - val_mean_absolute_error: 0.0470\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0035 - mean_absolute_error: 0.0370 - val_loss: 0.0035 - val_mean_absolute_error: 0.0425\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0039 - mean_absolute_error: 0.0376 - val_loss: 0.0038 - val_mean_absolute_error: 0.0449\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0037 - mean_absolute_error: 0.0367 - val_loss: 0.0061 - val_mean_absolute_error: 0.0550\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0044 - mean_absolute_error: 0.0396 - val_loss: 0.0047 - val_mean_absolute_error: 0.0480\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0038 - mean_absolute_error: 0.0372 - val_loss: 0.0037 - val_mean_absolute_error: 0.0444\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0033 - mean_absolute_error: 0.0349 - val_loss: 0.0038 - val_mean_absolute_error: 0.0444\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0036 - mean_absolute_error: 0.0378 - val_loss: 0.0035 - val_mean_absolute_error: 0.0434\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0031 - mean_absolute_error: 0.0333 - val_loss: 0.0033 - val_mean_absolute_error: 0.0433\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0030 - mean_absolute_error: 0.0336 - val_loss: 0.0033 - val_mean_absolute_error: 0.0428\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0036 - mean_absolute_error: 0.0367 - val_loss: 0.0036 - val_mean_absolute_error: 0.0456\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0031 - mean_absolute_error: 0.0329 - val_loss: 0.0034 - val_mean_absolute_error: 0.0433\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0032 - mean_absolute_error: 0.0342 - val_loss: 0.0037 - val_mean_absolute_error: 0.0434\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0036 - mean_absolute_error: 0.0367 - val_loss: 0.0036 - val_mean_absolute_error: 0.0433\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0031 - mean_absolute_error: 0.0337 - val_loss: 0.0040 - val_mean_absolute_error: 0.0494\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0031 - mean_absolute_error: 0.0340 - val_loss: 0.0030 - val_mean_absolute_error: 0.0409\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0031 - mean_absolute_error: 0.0344 - val_loss: 0.0032 - val_mean_absolute_error: 0.0434\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0028 - mean_absolute_error: 0.0330 - val_loss: 0.0036 - val_mean_absolute_error: 0.0465\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0033 - mean_absolute_error: 0.0344 - val_loss: 0.0035 - val_mean_absolute_error: 0.0442\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0028 - mean_absolute_error: 0.0328 - val_loss: 0.0038 - val_mean_absolute_error: 0.0454\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0032 - mean_absolute_error: 0.0329 - val_loss: 0.0033 - val_mean_absolute_error: 0.0419\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0027 - mean_absolute_error: 0.0322 - val_loss: 0.0031 - val_mean_absolute_error: 0.0425\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0035 - mean_absolute_error: 0.0346 - val_loss: 0.0061 - val_mean_absolute_error: 0.0555\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0033 - mean_absolute_error: 0.0334 - val_loss: 0.0033 - val_mean_absolute_error: 0.0421\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0033 - mean_absolute_error: 0.0341 - val_loss: 0.0032 - val_mean_absolute_error: 0.0436\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0031 - mean_absolute_error: 0.0325 - val_loss: 0.0034 - val_mean_absolute_error: 0.0431\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0027 - mean_absolute_error: 0.0311 - val_loss: 0.0030 - val_mean_absolute_error: 0.0416\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0022 - mean_absolute_error: 0.0289 - val_loss: 0.0052 - val_mean_absolute_error: 0.0514\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0026 - mean_absolute_error: 0.0302 - val_loss: 0.0062 - val_mean_absolute_error: 0.0563\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0023 - mean_absolute_error: 0.0299 - val_loss: 0.0035 - val_mean_absolute_error: 0.0453\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0023 - mean_absolute_error: 0.0288 - val_loss: 0.0030 - val_mean_absolute_error: 0.0426\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0029 - mean_absolute_error: 0.0330 - val_loss: 0.0032 - val_mean_absolute_error: 0.0430\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0029 - mean_absolute_error: 0.0323 - val_loss: 0.0032 - val_mean_absolute_error: 0.0415\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0026 - mean_absolute_error: 0.0304 - val_loss: 0.0031 - val_mean_absolute_error: 0.0430\n",
      "loss_training_history plot saved as 'loss_training_history_2024_07_14_16_48_40.png'\n",
      "MAE_training_history plot saved as 'MAE_training_history_2024_07_14_16_48_40.png'\n",
      "19/19 - 0s - 5ms/step - loss: 0.0031 - mean_absolute_error: 0.0466\n",
      "Test Loss: 0.0031\n",
      "Test MAE: 0.05\n",
      "MAE in dollars: +/- $1791.09\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Predicted_vs_Actual plot saved as 'Predicted_vs_Actual_2024_07_14_16_48_41.png'\n",
      "Residuals plot saved as 'Residuals_2024_07_14_16_48_41.png'\n",
      "(586, 1)\n",
      "Model saved successfully.\n",
      "[[Timestamp('2022-12-05 00:00:00') 17728.7890625]\n",
      " [Timestamp('2022-12-06 00:00:00') 17736.857421875]\n",
      " [Timestamp('2022-12-07 00:00:00') 17875.330078125]\n",
      " [Timestamp('2022-12-08 00:00:00') 17837.93359375]\n",
      " [Timestamp('2022-12-09 00:00:00') 17836.396484375]\n",
      " [Timestamp('2022-12-10 00:00:00') 17926.357421875]\n",
      " [Timestamp('2022-12-11 00:00:00') 17905.80078125]\n",
      " [Timestamp('2022-12-12 00:00:00') 17954.98046875]\n",
      " [Timestamp('2022-12-13 00:00:00') 18000.09765625]\n",
      " [Timestamp('2022-12-14 00:00:00') 18298.564453125]]\n",
      "Start                     2022-12-05 00:00:00\n",
      "End                       2024-07-13 00:00:00\n",
      "Duration                    586 days 00:00:00\n",
      "Exposure Time [%]                    90.11925\n",
      "Equity Final [$]               2163479.025137\n",
      "Equity Peak [$]                2185865.766668\n",
      "Return [%]                         116.347903\n",
      "Buy & Hold Return [%]              248.939969\n",
      "Return (Ann.) [%]                   61.584569\n",
      "Volatility (Ann.) [%]               42.281526\n",
      "Sharpe Ratio                         1.456536\n",
      "Sortino Ratio                        4.244432\n",
      "Calmar Ratio                         3.120583\n",
      "Max. Drawdown [%]                  -19.734956\n",
      "Avg. Drawdown [%]                   -2.220413\n",
      "Max. Drawdown Duration      102 days 00:00:00\n",
      "Avg. Drawdown Duration       16 days 00:00:00\n",
      "# Trades                                  314\n",
      "Win Rate [%]                        86.305732\n",
      "Best Trade [%]                      38.276178\n",
      "Worst Trade [%]                     -6.814773\n",
      "Avg. Trade [%]                      12.275378\n",
      "Max. Trade Duration         219 days 00:00:00\n",
      "Avg. Trade Duration          41 days 00:00:00\n",
      "Profit Factor                       43.841906\n",
      "Expectancy [%]                      12.836316\n",
      "SQN                                 21.066685\n",
      "_strategy                      SignalStrategy\n",
      "_equity_curve                             ...\n",
      "_trades                        Size  Entry...\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%d %b'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%m/%Y'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:455: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df2 = (df.assign(_width=1).set_index('datetime')\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:659: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:659: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, BatchNormalization, Bidirectional, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from plotting_utils import *\n",
    "from fetch_data import fetch_fear_and_greed_btc\n",
    "from generate_signals import generate_signal\n",
    "from backtester_utils import *\n",
    "from DataPreprocessor import DataPreprocessor\n",
    "from ModelEvaluator import ModelEvaluator\n",
    "\n",
    "\n",
    "class LSTMModel:\n",
    "    def __init__(self, model_path=None, data_path=None, lags=5, test_size=.25, learning_rate = 0.001, epochs=50, batch_size=32, validation_split=0.2, plot=True):\n",
    "        self.model = None\n",
    "        self.model_path = model_path\n",
    "        self.history = None\n",
    "        self.data_path = data_path\n",
    "        self.lag_features = ['value', 'Close'] # change these if you want to calculate lags on different feature columns\n",
    "        self.target_col = 'Close' # change this if you want to target a different variable than Close\n",
    "        self.X_scaler = RobustScaler()\n",
    "        self.y_scaler = RobustScaler()\n",
    "        self.preprocessor = DataPreprocessor(self.X_scaler, self.y_scaler, self.lag_features, lags, self.target_col, test_size)\n",
    "        self.current_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        self.learning_rate = learning_rate \n",
    "        self.loss = 'mean_squared_error' # change this if you're not going to solve for a regression target\n",
    "        self.metrics = ['mean_absolute_error']  # change this if you're not going to solve for a regression target\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "        self.plot = plot # set plot to false when instantiating if you dont want the backtest graph\n",
    "\n",
    "        if model_path:\n",
    "            self.load_saved_model(model_path)\n",
    "    \n",
    "    def load_saved_model(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "        print(f'Model loaded from {model_path}')\n",
    "\n",
    "    # Loads Data from a User-fed CSV Path, if CSV passed\n",
    "    def load_data(self):\n",
    "        if self.data_path is None:\n",
    "            print(\"No data path preloaded. Downloading Fear and Greed and BTC data...\")\n",
    "            self.data = fetch_fear_and_greed_btc()\n",
    "        else:\n",
    "            print(\"Data path preloaded. saving csv to dataframe...\")\n",
    "            self.data = pd.read_csv(self.data_path, parse_dates=True, index_col='timestamp') \n",
    "\n",
    "    def preprocess_data(self):\n",
    "        (\n",
    "            self.X_train_scaled,\n",
    "            self.X_test_scaled,\n",
    "            self.y_train_scaled,\n",
    "            self.y_test_scaled,\n",
    "            self.X_test,\n",
    "            self.y_test,\n",
    "            self.dates_train,\n",
    "            self.dates_test,\n",
    "            self.features_test_df\n",
    "        ) = self.preprocessor.preprocess_data(self.data)\n",
    "        print(self.X_train_scaled.shape)\n",
    "    \n",
    "    def reshape_for_lstm(self):\n",
    "        self.X_train_scaled = self.X_train_scaled.reshape((self.X_train_scaled.shape[0], self.X_train_scaled.shape[1], self.X_train_scaled.shape[2]))\n",
    "        self.X_test_scaled = self.X_test_scaled.reshape((self.X_test_scaled.shape[0], self.X_test_scaled.shape[1], self.X_test_scaled.shape[2]))\n",
    "\n",
    "    def build_model_lstm(self):\n",
    "        self.reshape_for_lstm()\n",
    "        timesteps = self.X_train_scaled.shape[1] \n",
    "        features = self.X_train_scaled.shape[2] \n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(timesteps, features)))\n",
    "        model.add(LSTM(517, return_sequences=False))\n",
    "        model.add(Dropout(0.4808067231743268)) # Dropout Regularization\n",
    "        # model.add(LSTM(120, return_sequences=False))\n",
    "        # model.add(Dropout(0.23702192322434543)) # Dropout Regularization\n",
    "        model.add(Dense(36, activation='relu'))\n",
    "        # model.add(BatchNormalization()) # Batch Normalization\n",
    "        # model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(1))  # No activation for regression\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss=self.loss, metrics=self.metrics)\n",
    "        model.summary()\n",
    "        self.model = model\n",
    "        save_and_visualize_model(self.model)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.history = self.model.fit(\n",
    "            self.X_train_scaled, \n",
    "            self.y_train_scaled, \n",
    "            epochs = self.epochs, \n",
    "            batch_size = self.batch_size, \n",
    "            validation_split = self.validation_split, \n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        plot_loss_training_history(self.history)\n",
    "        plot_mae_training_history(self.history)\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        self.evaluator = ModelEvaluator(self.model, self.X_test, self.y_test, self.X_test_scaled, self.y_test_scaled, self.y_scaler)\n",
    "        self.evaluator.evaluate_model()\n",
    "        # self.evaluator.atr_to_data()\n",
    "    \n",
    "    def predict_model(self):\n",
    "        self.predictions_inversed = self.evaluator.predict_model()\n",
    "        print(self.predictions_inversed.shape)\n",
    "\n",
    "    def save_model(self):  \n",
    "        self.model_path = f'{self.current_timestamp}_LSTM_model_epochs_{self.epochs}.keras'\n",
    "        self.model.save(self.model_path)\n",
    "        print(\"Model saved successfully.\")\n",
    "\n",
    "    def generate_model_signals(self):\n",
    "        self.X_test = generate_signal(self.features_test_df, self.predictions_inversed, self.dates_test)\n",
    "        # print(self.X_test)\n",
    "\n",
    "    def backtest_signals(self):\n",
    "        run_backtest(data=self.X_test, plot=self.plot)\n",
    "\n",
    "    def run_and_train(self):\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.build_model_lstm()\n",
    "        self.train_model()\n",
    "        self.plot_training_history()\n",
    "        self.evaluate_model()\n",
    "        self.predict_model()\n",
    "        self.save_model()\n",
    "        self.generate_model_signals()\n",
    "        self.backtest_signals()\n",
    "\n",
    "    def run_with_pretrained(self):\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.reshape_for_lstm()\n",
    "        self.evaluate_model()\n",
    "        self.predict_model()\n",
    "        self.generate_model_signals()\n",
    "        self.backtest_signals()\n",
    "\n",
    "\n",
    "model = LSTMModel(#model_path = 'backtests/Low_MAE/backtest_3/2024_07_08_01_38_10_LSTM_model_epochs_145.keras',\n",
    "                  #data_path='fear_greed_btc_combined.csv',\n",
    "                  test_size=0.25, \n",
    "                  learning_rate=0.0005514365217126862, \n",
    "                  epochs=50, \n",
    "                  batch_size=122, \n",
    "                  validation_split=0.25, \n",
    "                  plot=True)\n",
    "\n",
    "model.run_and_train()\n",
    "# model.run_with_pretrained()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the optimizer code. Run this to fine tune your model's hyper parameters and get better predicitve capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[I 2024-07-14 16:48:42,426] A new study created in memory with name: no-name-e778229e-d210-4e65-be71-4ccd65513f17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fear and Greed Index data has been saved to 'fear_and_greed_index.csv'.\n",
      "Combined data has been saved to 'fear_greed_btc_combined.csv'.\n",
      "X_train_scaled shape: (1756, 5, 15)\n",
      "X_test_scaled shape: (586, 5, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 16:49:10,809] Trial 0 finished with value: 0.6031091809272766 and parameters: {'LSTM Neurons_0': 195, 'Dropout Rate_0': 0.14815256529010098, 'Dense Neurons': 25, 'learning_rate': 0.0634698385268798}. Best is trial 0 with value: 0.6031091809272766.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1752, 5, 15)\n",
      "X_test_scaled shape: (585, 5, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 16:49:33,197] Trial 1 finished with value: 0.10376796126365662 and parameters: {'LSTM Neurons_0': 142, 'Dropout Rate_0': 0.07926177775672458, 'Dense Neurons': 24, 'learning_rate': 0.0008583643077005941}. Best is trial 1 with value: 0.10376796126365662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1749, 5, 15)\n",
      "X_test_scaled shape: (583, 5, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 16:49:46,278] Trial 2 finished with value: 0.20825140178203583 and parameters: {'LSTM Neurons_0': 62, 'Dropout Rate_0': 0.18548518261177485, 'Dense Neurons': 24, 'learning_rate': 0.00666277595506283}. Best is trial 1 with value: 0.10376796126365662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1745, 5, 15)\n",
      "X_test_scaled shape: (582, 5, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 16:49:56,790] Trial 3 finished with value: 0.5589978694915771 and parameters: {'LSTM Neurons_0': 40, 'Dropout Rate_0': 0.25077378287245183, 'Dense Neurons': 28, 'learning_rate': 0.06383169456742115}. Best is trial 1 with value: 0.10376796126365662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1741, 5, 15)\n",
      "X_test_scaled shape: (581, 5, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 16:50:20,267] Trial 4 finished with value: 0.5693777203559875 and parameters: {'LSTM Neurons_0': 163, 'Dropout Rate_0': 0.20365115619612856, 'Dense Neurons': 4, 'learning_rate': 0.03626131448544172}. Best is trial 1 with value: 0.10376796126365662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 5\n",
      "Best trial:\n",
      "  Value: 0.10376796126365662\n",
      "  Params: \n",
      "    LSTM Neurons_0: 142\n",
      "    Dropout Rate_0: 0.07926177775672458\n",
      "    Dense Neurons: 24\n",
      "    learning_rate: 0.0008583643077005941\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "from keras.backend import clear_session\n",
    "from keras.layers import Input, LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from fetch_data import fetch_fear_and_greed_btc\n",
    "from DataPreprocessor import DataPreprocessor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "data = fetch_fear_and_greed_btc()\n",
    "X_scaler = RobustScaler()\n",
    "y_scaler = RobustScaler()\n",
    "preprocessor = DataPreprocessor(X_scaler, y_scaler)\n",
    "\n",
    "BATCHSIZE = 64\n",
    "VALIDATION_SPLIT = 0.25\n",
    "CLASSES = 10\n",
    "EPOCHS = 200\n",
    "\n",
    "def objective(trial):\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, _, _, _, _, _ = preprocessor.preprocess_data(data)\n",
    "\n",
    "    # Print shapes for debugging\n",
    "    print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "    print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], X_train_scaled.shape[2])) \n",
    "    X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], X_test_scaled.shape[2]))\n",
    "\n",
    "    timesteps = X_train_scaled.shape[1] \n",
    "    features = X_train_scaled.shape[2]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(timesteps, features)))\n",
    "    model.add(LSTM(units=trial.suggest_int('LSTM Neurons_0', 10, 200), return_sequences=True))\n",
    "    model.add(Dropout(trial.suggest_float('Dropout Rate_0', .0001, .50)))\n",
    "    # model.add(LSTM(units=trial.suggest_int('LSTM Neurons_1', 10, 1000), return_sequences=False))\n",
    "    # model.add(Dropout(trial.suggest_float('Dropout Rate_1 ', .0001, .50)))\n",
    "    model.add(Dense(trial.suggest_int('Dense Neurons', 1, 50), activation='relu'))\n",
    "    model.add(Dense(1))  # No activation for regression\n",
    "\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=['mean_absolute_error']\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train_scaled,\n",
    "        # validation_data=(X_test_scaled, y_test_scaled),\n",
    "        shuffle=False,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCHSIZE,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    \n",
    "    study.optimize(objective, n_trials=5, timeout=100_000)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is another instance of the LSTMModel Class, using example optimization parameters above. You can change this as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data path preloaded. Downloading Fear and Greed and BTC data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fear and Greed Index data has been saved to 'fear_and_greed_index.csv'.\n",
      "Combined data has been saved to 'fear_greed_btc_combined.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1756, 5, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">517</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,102,244</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">517</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m517\u001b[0m)            │     \u001b[38;5;34m1,102,244\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m517\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │        \u001b[38;5;34m18,648\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120,929</span> (4.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,120,929\u001b[0m (4.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,120,929</span> (4.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,120,929\u001b[0m (4.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Model visualization saved and displayed from /Users/joshbazz/Desktop/Bootcamp/fear-greed-lstm/model_2024_07_14_16_50_21.png\n",
      "Epoch 1/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1625 - mean_absolute_error: 0.2244 - val_loss: 0.0247 - val_mean_absolute_error: 0.1225\n",
      "Epoch 2/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0251 - mean_absolute_error: 0.1015 - val_loss: 0.0107 - val_mean_absolute_error: 0.0843\n",
      "Epoch 3/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0101 - mean_absolute_error: 0.0706 - val_loss: 0.0151 - val_mean_absolute_error: 0.0874\n",
      "Epoch 4/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - mean_absolute_error: 0.0572 - val_loss: 0.0060 - val_mean_absolute_error: 0.0545\n",
      "Epoch 5/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mean_absolute_error: 0.0525 - val_loss: 0.0054 - val_mean_absolute_error: 0.0548\n",
      "Epoch 6/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0057 - mean_absolute_error: 0.0474 - val_loss: 0.0061 - val_mean_absolute_error: 0.0562\n",
      "Epoch 7/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mean_absolute_error: 0.0421 - val_loss: 0.0051 - val_mean_absolute_error: 0.0511\n",
      "Epoch 8/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0053 - mean_absolute_error: 0.0463 - val_loss: 0.0044 - val_mean_absolute_error: 0.0480\n",
      "Epoch 9/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0051 - mean_absolute_error: 0.0437 - val_loss: 0.0066 - val_mean_absolute_error: 0.0580\n",
      "Epoch 10/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mean_absolute_error: 0.0423 - val_loss: 0.0072 - val_mean_absolute_error: 0.0604\n",
      "Epoch 11/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mean_absolute_error: 0.0434 - val_loss: 0.0054 - val_mean_absolute_error: 0.0559\n",
      "Epoch 12/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0046 - mean_absolute_error: 0.0415 - val_loss: 0.0067 - val_mean_absolute_error: 0.0583\n",
      "Epoch 13/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0040 - mean_absolute_error: 0.0401 - val_loss: 0.0050 - val_mean_absolute_error: 0.0504\n",
      "Epoch 14/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0035 - mean_absolute_error: 0.0383 - val_loss: 0.0040 - val_mean_absolute_error: 0.0459\n",
      "Epoch 15/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mean_absolute_error: 0.0405 - val_loss: 0.0040 - val_mean_absolute_error: 0.0455\n",
      "Epoch 16/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0037 - mean_absolute_error: 0.0387 - val_loss: 0.0040 - val_mean_absolute_error: 0.0464\n",
      "Epoch 17/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0045 - mean_absolute_error: 0.0385 - val_loss: 0.0042 - val_mean_absolute_error: 0.0471\n",
      "Epoch 18/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0036 - mean_absolute_error: 0.0368 - val_loss: 0.0053 - val_mean_absolute_error: 0.0518\n",
      "Epoch 19/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0037 - mean_absolute_error: 0.0371 - val_loss: 0.0057 - val_mean_absolute_error: 0.0539\n",
      "Epoch 20/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0041 - mean_absolute_error: 0.0372 - val_loss: 0.0044 - val_mean_absolute_error: 0.0473\n",
      "Epoch 21/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0038 - mean_absolute_error: 0.0370 - val_loss: 0.0072 - val_mean_absolute_error: 0.0609\n",
      "Epoch 22/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0038 - mean_absolute_error: 0.0371 - val_loss: 0.0037 - val_mean_absolute_error: 0.0445\n",
      "Epoch 23/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0032 - mean_absolute_error: 0.0348 - val_loss: 0.0068 - val_mean_absolute_error: 0.0595\n",
      "Epoch 24/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0034 - mean_absolute_error: 0.0354 - val_loss: 0.0072 - val_mean_absolute_error: 0.0599\n",
      "Epoch 25/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mean_absolute_error: 0.0385 - val_loss: 0.0051 - val_mean_absolute_error: 0.0506\n",
      "Epoch 26/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0033 - mean_absolute_error: 0.0350 - val_loss: 0.0043 - val_mean_absolute_error: 0.0458\n",
      "Epoch 27/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0036 - mean_absolute_error: 0.0363 - val_loss: 0.0033 - val_mean_absolute_error: 0.0430\n",
      "Epoch 28/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0034 - mean_absolute_error: 0.0356 - val_loss: 0.0034 - val_mean_absolute_error: 0.0425\n",
      "Epoch 29/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0033 - mean_absolute_error: 0.0339 - val_loss: 0.0050 - val_mean_absolute_error: 0.0498\n",
      "Epoch 30/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0037 - mean_absolute_error: 0.0360 - val_loss: 0.0044 - val_mean_absolute_error: 0.0474\n",
      "Epoch 31/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0032 - mean_absolute_error: 0.0340 - val_loss: 0.0036 - val_mean_absolute_error: 0.0463\n",
      "Epoch 32/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0035 - mean_absolute_error: 0.0348 - val_loss: 0.0043 - val_mean_absolute_error: 0.0514\n",
      "Epoch 33/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0036 - mean_absolute_error: 0.0355 - val_loss: 0.0038 - val_mean_absolute_error: 0.0452\n",
      "Epoch 34/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0028 - mean_absolute_error: 0.0317 - val_loss: 0.0040 - val_mean_absolute_error: 0.0453\n",
      "Epoch 35/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0029 - mean_absolute_error: 0.0330 - val_loss: 0.0055 - val_mean_absolute_error: 0.0524\n",
      "Epoch 36/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0035 - mean_absolute_error: 0.0349 - val_loss: 0.0084 - val_mean_absolute_error: 0.0648\n",
      "Epoch 37/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0037 - mean_absolute_error: 0.0346 - val_loss: 0.0045 - val_mean_absolute_error: 0.0481\n",
      "Epoch 38/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0027 - mean_absolute_error: 0.0306 - val_loss: 0.0060 - val_mean_absolute_error: 0.0551\n",
      "Epoch 39/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0027 - mean_absolute_error: 0.0305 - val_loss: 0.0043 - val_mean_absolute_error: 0.0477\n",
      "Epoch 40/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0026 - mean_absolute_error: 0.0305 - val_loss: 0.0038 - val_mean_absolute_error: 0.0454\n",
      "Epoch 41/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0025 - mean_absolute_error: 0.0301 - val_loss: 0.0036 - val_mean_absolute_error: 0.0448\n",
      "Epoch 42/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0027 - mean_absolute_error: 0.0311 - val_loss: 0.0029 - val_mean_absolute_error: 0.0406\n",
      "Epoch 43/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0026 - mean_absolute_error: 0.0296 - val_loss: 0.0038 - val_mean_absolute_error: 0.0441\n",
      "Epoch 44/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0026 - mean_absolute_error: 0.0304 - val_loss: 0.0037 - val_mean_absolute_error: 0.0462\n",
      "Epoch 45/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0028 - mean_absolute_error: 0.0311 - val_loss: 0.0029 - val_mean_absolute_error: 0.0395\n",
      "Epoch 46/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0029 - mean_absolute_error: 0.0315 - val_loss: 0.0032 - val_mean_absolute_error: 0.0407\n",
      "Epoch 47/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0028 - mean_absolute_error: 0.0310 - val_loss: 0.0048 - val_mean_absolute_error: 0.0550\n",
      "Epoch 48/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0032 - mean_absolute_error: 0.0336 - val_loss: 0.0035 - val_mean_absolute_error: 0.0440\n",
      "Epoch 49/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0026 - mean_absolute_error: 0.0312 - val_loss: 0.0038 - val_mean_absolute_error: 0.0442\n",
      "Epoch 50/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0028 - mean_absolute_error: 0.0307 - val_loss: 0.0051 - val_mean_absolute_error: 0.0511\n",
      "Epoch 51/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0026 - mean_absolute_error: 0.0300 - val_loss: 0.0048 - val_mean_absolute_error: 0.0494\n",
      "Epoch 52/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0027 - mean_absolute_error: 0.0303 - val_loss: 0.0029 - val_mean_absolute_error: 0.0409\n",
      "Epoch 53/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0028 - mean_absolute_error: 0.0305 - val_loss: 0.0029 - val_mean_absolute_error: 0.0398\n",
      "Epoch 54/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0026 - mean_absolute_error: 0.0295 - val_loss: 0.0028 - val_mean_absolute_error: 0.0382\n",
      "Epoch 55/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0022 - mean_absolute_error: 0.0276 - val_loss: 0.0031 - val_mean_absolute_error: 0.0429\n",
      "Epoch 56/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0032 - mean_absolute_error: 0.0313 - val_loss: 0.0036 - val_mean_absolute_error: 0.0445\n",
      "Epoch 57/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0025 - mean_absolute_error: 0.0298 - val_loss: 0.0085 - val_mean_absolute_error: 0.0659\n",
      "Epoch 58/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0028 - mean_absolute_error: 0.0305 - val_loss: 0.0041 - val_mean_absolute_error: 0.0463\n",
      "Epoch 59/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0022 - mean_absolute_error: 0.0272 - val_loss: 0.0028 - val_mean_absolute_error: 0.0400\n",
      "Epoch 60/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0022 - mean_absolute_error: 0.0279 - val_loss: 0.0033 - val_mean_absolute_error: 0.0424\n",
      "Epoch 61/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0023 - mean_absolute_error: 0.0273 - val_loss: 0.0029 - val_mean_absolute_error: 0.0421\n",
      "Epoch 62/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0031 - mean_absolute_error: 0.0304 - val_loss: 0.0041 - val_mean_absolute_error: 0.0451\n",
      "Epoch 63/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0023 - mean_absolute_error: 0.0282 - val_loss: 0.0033 - val_mean_absolute_error: 0.0421\n",
      "Epoch 64/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0026 - mean_absolute_error: 0.0301 - val_loss: 0.0039 - val_mean_absolute_error: 0.0443\n",
      "Epoch 65/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0028 - mean_absolute_error: 0.0308 - val_loss: 0.0027 - val_mean_absolute_error: 0.0394\n",
      "Epoch 66/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0024 - mean_absolute_error: 0.0283 - val_loss: 0.0027 - val_mean_absolute_error: 0.0397\n",
      "Epoch 67/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0028 - mean_absolute_error: 0.0299 - val_loss: 0.0050 - val_mean_absolute_error: 0.0504\n",
      "Epoch 68/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0031 - mean_absolute_error: 0.0313 - val_loss: 0.0115 - val_mean_absolute_error: 0.0769\n",
      "Epoch 69/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0037 - mean_absolute_error: 0.0339 - val_loss: 0.0034 - val_mean_absolute_error: 0.0432\n",
      "Epoch 70/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0025 - mean_absolute_error: 0.0278 - val_loss: 0.0037 - val_mean_absolute_error: 0.0450\n",
      "Epoch 71/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0022 - mean_absolute_error: 0.0276 - val_loss: 0.0030 - val_mean_absolute_error: 0.0428\n",
      "Epoch 72/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0022 - mean_absolute_error: 0.0268 - val_loss: 0.0042 - val_mean_absolute_error: 0.0535\n",
      "Epoch 73/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0031 - mean_absolute_error: 0.0309 - val_loss: 0.0039 - val_mean_absolute_error: 0.0497\n",
      "Epoch 74/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0029 - mean_absolute_error: 0.0300 - val_loss: 0.0032 - val_mean_absolute_error: 0.0424\n",
      "Epoch 75/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0031 - mean_absolute_error: 0.0316 - val_loss: 0.0043 - val_mean_absolute_error: 0.0473\n",
      "Epoch 76/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0025 - mean_absolute_error: 0.0291 - val_loss: 0.0090 - val_mean_absolute_error: 0.0695\n",
      "Epoch 77/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0028 - mean_absolute_error: 0.0300 - val_loss: 0.0027 - val_mean_absolute_error: 0.0400\n",
      "Epoch 78/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0026 - mean_absolute_error: 0.0290 - val_loss: 0.0024 - val_mean_absolute_error: 0.0371\n",
      "Epoch 79/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0025 - mean_absolute_error: 0.0282 - val_loss: 0.0030 - val_mean_absolute_error: 0.0436\n",
      "Epoch 80/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0026 - mean_absolute_error: 0.0279 - val_loss: 0.0027 - val_mean_absolute_error: 0.0387\n",
      "Epoch 81/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0026 - mean_absolute_error: 0.0294 - val_loss: 0.0044 - val_mean_absolute_error: 0.0475\n",
      "Epoch 82/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0026 - mean_absolute_error: 0.0282 - val_loss: 0.0036 - val_mean_absolute_error: 0.0428\n",
      "Epoch 83/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0022 - mean_absolute_error: 0.0275 - val_loss: 0.0023 - val_mean_absolute_error: 0.0360\n",
      "Epoch 84/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0022 - mean_absolute_error: 0.0284 - val_loss: 0.0051 - val_mean_absolute_error: 0.0564\n",
      "Epoch 85/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0026 - mean_absolute_error: 0.0284 - val_loss: 0.0026 - val_mean_absolute_error: 0.0368\n",
      "Epoch 86/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0019 - mean_absolute_error: 0.0261 - val_loss: 0.0024 - val_mean_absolute_error: 0.0360\n",
      "Epoch 87/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0022 - mean_absolute_error: 0.0267 - val_loss: 0.0023 - val_mean_absolute_error: 0.0364\n",
      "Epoch 88/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0022 - mean_absolute_error: 0.0272 - val_loss: 0.0022 - val_mean_absolute_error: 0.0340\n",
      "Epoch 89/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0026 - mean_absolute_error: 0.0292 - val_loss: 0.0040 - val_mean_absolute_error: 0.0450\n",
      "Epoch 90/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0020 - mean_absolute_error: 0.0267 - val_loss: 0.0025 - val_mean_absolute_error: 0.0364\n",
      "Epoch 91/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0024 - mean_absolute_error: 0.0278 - val_loss: 0.0024 - val_mean_absolute_error: 0.0370\n",
      "Epoch 92/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0019 - mean_absolute_error: 0.0257 - val_loss: 0.0028 - val_mean_absolute_error: 0.0412\n",
      "Epoch 93/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0020 - mean_absolute_error: 0.0263 - val_loss: 0.0060 - val_mean_absolute_error: 0.0554\n",
      "Epoch 94/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0021 - mean_absolute_error: 0.0271 - val_loss: 0.0036 - val_mean_absolute_error: 0.0436\n",
      "Epoch 95/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0020 - mean_absolute_error: 0.0263 - val_loss: 0.0032 - val_mean_absolute_error: 0.0459\n",
      "Epoch 96/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0024 - mean_absolute_error: 0.0275 - val_loss: 0.0026 - val_mean_absolute_error: 0.0399\n",
      "Epoch 97/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0024 - mean_absolute_error: 0.0282 - val_loss: 0.0023 - val_mean_absolute_error: 0.0364\n",
      "Epoch 98/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0024 - mean_absolute_error: 0.0270 - val_loss: 0.0036 - val_mean_absolute_error: 0.0485\n",
      "Epoch 99/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0025 - mean_absolute_error: 0.0294 - val_loss: 0.0025 - val_mean_absolute_error: 0.0384\n",
      "Epoch 100/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0024 - mean_absolute_error: 0.0274 - val_loss: 0.0025 - val_mean_absolute_error: 0.0371\n",
      "Epoch 101/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0024 - mean_absolute_error: 0.0282 - val_loss: 0.0029 - val_mean_absolute_error: 0.0383\n",
      "Epoch 102/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0022 - mean_absolute_error: 0.0262 - val_loss: 0.0031 - val_mean_absolute_error: 0.0443\n",
      "Epoch 103/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0025 - mean_absolute_error: 0.0275 - val_loss: 0.0024 - val_mean_absolute_error: 0.0363\n",
      "Epoch 104/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0022 - mean_absolute_error: 0.0264 - val_loss: 0.0044 - val_mean_absolute_error: 0.0471\n",
      "Epoch 105/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0026 - mean_absolute_error: 0.0276 - val_loss: 0.0053 - val_mean_absolute_error: 0.0511\n",
      "Epoch 106/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0023 - mean_absolute_error: 0.0264 - val_loss: 0.0024 - val_mean_absolute_error: 0.0362\n",
      "Epoch 107/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0021 - mean_absolute_error: 0.0255 - val_loss: 0.0025 - val_mean_absolute_error: 0.0392\n",
      "Epoch 108/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0022 - mean_absolute_error: 0.0266 - val_loss: 0.0023 - val_mean_absolute_error: 0.0363\n",
      "Epoch 109/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0019 - mean_absolute_error: 0.0257 - val_loss: 0.0021 - val_mean_absolute_error: 0.0339\n",
      "Epoch 110/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0016 - mean_absolute_error: 0.0238 - val_loss: 0.0021 - val_mean_absolute_error: 0.0343\n",
      "Epoch 111/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0019 - mean_absolute_error: 0.0244 - val_loss: 0.0029 - val_mean_absolute_error: 0.0395\n",
      "Epoch 112/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0021 - mean_absolute_error: 0.0258 - val_loss: 0.0029 - val_mean_absolute_error: 0.0391\n",
      "Epoch 113/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0019 - mean_absolute_error: 0.0242 - val_loss: 0.0021 - val_mean_absolute_error: 0.0336\n",
      "Epoch 114/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - mean_absolute_error: 0.0258 - val_loss: 0.0024 - val_mean_absolute_error: 0.0360\n",
      "Epoch 115/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0016 - mean_absolute_error: 0.0237 - val_loss: 0.0020 - val_mean_absolute_error: 0.0334\n",
      "Epoch 116/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0025 - mean_absolute_error: 0.0275 - val_loss: 0.0024 - val_mean_absolute_error: 0.0359\n",
      "Epoch 117/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0020 - mean_absolute_error: 0.0257 - val_loss: 0.0023 - val_mean_absolute_error: 0.0372\n",
      "Epoch 118/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0023 - mean_absolute_error: 0.0276 - val_loss: 0.0030 - val_mean_absolute_error: 0.0434\n",
      "Epoch 119/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0026 - mean_absolute_error: 0.0297 - val_loss: 0.0030 - val_mean_absolute_error: 0.0448\n",
      "Epoch 120/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - mean_absolute_error: 0.0252 - val_loss: 0.0025 - val_mean_absolute_error: 0.0377\n",
      "Epoch 121/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0024 - mean_absolute_error: 0.0267 - val_loss: 0.0036 - val_mean_absolute_error: 0.0430\n",
      "Epoch 122/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0022 - mean_absolute_error: 0.0262 - val_loss: 0.0023 - val_mean_absolute_error: 0.0373\n",
      "Epoch 123/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0020 - mean_absolute_error: 0.0254 - val_loss: 0.0027 - val_mean_absolute_error: 0.0414\n",
      "Epoch 124/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0025 - mean_absolute_error: 0.0279 - val_loss: 0.0030 - val_mean_absolute_error: 0.0446\n",
      "Epoch 125/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0022 - mean_absolute_error: 0.0269 - val_loss: 0.0023 - val_mean_absolute_error: 0.0372\n",
      "Epoch 126/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - mean_absolute_error: 0.0250 - val_loss: 0.0027 - val_mean_absolute_error: 0.0383\n",
      "Epoch 127/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0019 - mean_absolute_error: 0.0245 - val_loss: 0.0022 - val_mean_absolute_error: 0.0348\n",
      "Epoch 128/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0017 - mean_absolute_error: 0.0234 - val_loss: 0.0021 - val_mean_absolute_error: 0.0357\n",
      "Epoch 129/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0019 - mean_absolute_error: 0.0252 - val_loss: 0.0021 - val_mean_absolute_error: 0.0350\n",
      "Epoch 130/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0018 - mean_absolute_error: 0.0246 - val_loss: 0.0038 - val_mean_absolute_error: 0.0445\n",
      "Epoch 131/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0020 - mean_absolute_error: 0.0247 - val_loss: 0.0023 - val_mean_absolute_error: 0.0364\n",
      "Epoch 132/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0019 - mean_absolute_error: 0.0244 - val_loss: 0.0021 - val_mean_absolute_error: 0.0346\n",
      "Epoch 133/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0020 - mean_absolute_error: 0.0256 - val_loss: 0.0023 - val_mean_absolute_error: 0.0371\n",
      "Epoch 134/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0018 - mean_absolute_error: 0.0246 - val_loss: 0.0032 - val_mean_absolute_error: 0.0409\n",
      "Epoch 135/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0020 - mean_absolute_error: 0.0243 - val_loss: 0.0028 - val_mean_absolute_error: 0.0386\n",
      "Epoch 136/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0016 - mean_absolute_error: 0.0234 - val_loss: 0.0023 - val_mean_absolute_error: 0.0366\n",
      "Epoch 137/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - mean_absolute_error: 0.0255 - val_loss: 0.0025 - val_mean_absolute_error: 0.0374\n",
      "Epoch 138/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0017 - mean_absolute_error: 0.0238 - val_loss: 0.0029 - val_mean_absolute_error: 0.0393\n",
      "Epoch 139/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0019 - mean_absolute_error: 0.0251 - val_loss: 0.0022 - val_mean_absolute_error: 0.0354\n",
      "Epoch 140/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0016 - mean_absolute_error: 0.0229 - val_loss: 0.0028 - val_mean_absolute_error: 0.0439\n",
      "Epoch 141/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mean_absolute_error: 0.0240 - val_loss: 0.0022 - val_mean_absolute_error: 0.0355\n",
      "Epoch 142/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0020 - mean_absolute_error: 0.0239 - val_loss: 0.0031 - val_mean_absolute_error: 0.0422\n",
      "Epoch 143/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0018 - mean_absolute_error: 0.0247 - val_loss: 0.0036 - val_mean_absolute_error: 0.0445\n",
      "Epoch 144/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0018 - mean_absolute_error: 0.0236 - val_loss: 0.0022 - val_mean_absolute_error: 0.0354\n",
      "Epoch 145/145\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0018 - mean_absolute_error: 0.0245 - val_loss: 0.0026 - val_mean_absolute_error: 0.0367\n",
      "loss_training_history plot saved as 'loss_training_history_2024_07_14_16_51_14.png'\n",
      "MAE_training_history plot saved as 'MAE_training_history_2024_07_14_16_51_15.png'\n",
      "19/19 - 0s - 6ms/step - loss: 0.0027 - mean_absolute_error: 0.0347\n",
      "Test Loss: 0.0027\n",
      "Test MAE: 0.03\n",
      "MAE in dollars: +/- $1335.26\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Predicted_vs_Actual plot saved as 'Predicted_vs_Actual_2024_07_14_16_51_15.png'\n",
      "Residuals plot saved as 'Residuals_2024_07_14_16_51_15.png'\n",
      "(586, 1)\n",
      "Model saved successfully.\n",
      "[[Timestamp('2022-12-05 00:00:00') 17578.99609375]\n",
      " [Timestamp('2022-12-06 00:00:00') 17551.953125]\n",
      " [Timestamp('2022-12-07 00:00:00') 17645.556640625]\n",
      " [Timestamp('2022-12-08 00:00:00') 17498.92578125]\n",
      " [Timestamp('2022-12-09 00:00:00') 17591.498046875]\n",
      " [Timestamp('2022-12-10 00:00:00') 17638.68359375]\n",
      " [Timestamp('2022-12-11 00:00:00') 17610.140625]\n",
      " [Timestamp('2022-12-12 00:00:00') 17678.318359375]\n",
      " [Timestamp('2022-12-13 00:00:00') 17827.26953125]\n",
      " [Timestamp('2022-12-14 00:00:00') 18279.828125]]\n",
      "Start                     2022-12-05 00:00:00\n",
      "End                       2024-07-13 00:00:00\n",
      "Duration                    586 days 00:00:00\n",
      "Exposure Time [%]                   68.824532\n",
      "Equity Final [$]                1486005.36734\n",
      "Equity Peak [$]                1489535.823926\n",
      "Return [%]                          48.600537\n",
      "Buy & Hold Return [%]              248.939969\n",
      "Return (Ann.) [%]                    27.92731\n",
      "Volatility (Ann.) [%]               16.720856\n",
      "Sharpe Ratio                         1.670208\n",
      "Sortino Ratio                        4.493039\n",
      "Calmar Ratio                         3.433654\n",
      "Max. Drawdown [%]                   -8.133408\n",
      "Avg. Drawdown [%]                   -1.280604\n",
      "Max. Drawdown Duration      193 days 00:00:00\n",
      "Avg. Drawdown Duration       25 days 00:00:00\n",
      "# Trades                                  362\n",
      "Win Rate [%]                        70.165746\n",
      "Best Trade [%]                      38.276178\n",
      "Worst Trade [%]                    -12.161678\n",
      "Avg. Trade [%]                       5.974423\n",
      "Max. Trade Duration          46 days 00:00:00\n",
      "Avg. Trade Duration          12 days 00:00:00\n",
      "Profit Factor                        6.024651\n",
      "Expectancy [%]                       6.641388\n",
      "SQN                                  9.754694\n",
      "_strategy                      SignalStrategy\n",
      "_equity_curve                             ...\n",
      "_trades                        Size  Entry...\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%d %b'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%m/%Y'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:455: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df2 = (df.assign(_width=1).set_index('datetime')\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:659: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:659: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, BatchNormalization, Bidirectional, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from plotting_utils import *\n",
    "from fetch_data import fetch_fear_and_greed_btc\n",
    "from generate_signals import generate_signal\n",
    "from backtester_utils import *\n",
    "from DataPreprocessor import DataPreprocessor\n",
    "from ModelEvaluator import ModelEvaluator\n",
    "\n",
    "\n",
    "class LSTMModel:\n",
    "    def __init__(self, model_path=None, data_path=None, lags=5, test_size=.25, learning_rate = 0.001, epochs=50, batch_size=32, validation_split=0.2, plot=True):\n",
    "        self.model = None\n",
    "        self.model_path = model_path\n",
    "        self.history = None\n",
    "        self.data_path = data_path\n",
    "        self.lag_features = ['value', 'Close'] # change these if you want to calculate lags on different feature columns\n",
    "        self.target_col = 'Close' # change this if you want to target a different variable than Close\n",
    "        self.X_scaler = RobustScaler()\n",
    "        self.y_scaler = RobustScaler()\n",
    "        self.preprocessor = DataPreprocessor(self.X_scaler, self.y_scaler, self.lag_features, lags, self.target_col, test_size)\n",
    "        self.current_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        self.learning_rate = learning_rate \n",
    "        self.loss = 'mean_squared_error' # change this if you're not going to solve for a regression target\n",
    "        self.metrics = ['mean_absolute_error']  # change this if you're not going to solve for a regression target\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "        self.plot = plot # set plot to false when instantiating if you dont want the backtest graph\n",
    "\n",
    "        if model_path:\n",
    "            self.load_saved_model(model_path)\n",
    "    \n",
    "    def load_saved_model(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "        print(f'Model loaded from {model_path}')\n",
    "\n",
    "    # Loads Data from a User-fed CSV Path, if CSV passed\n",
    "    def load_data(self):\n",
    "        if self.data_path is None:\n",
    "            print(\"No data path preloaded. Downloading Fear and Greed and BTC data...\")\n",
    "            self.data = fetch_fear_and_greed_btc()\n",
    "        else:\n",
    "            print(\"Data path preloaded. saving csv to dataframe...\")\n",
    "            self.data = pd.read_csv(self.data_path, parse_dates=True, index_col='timestamp') \n",
    "\n",
    "    def preprocess_data(self):\n",
    "        (\n",
    "            self.X_train_scaled,\n",
    "            self.X_test_scaled,\n",
    "            self.y_train_scaled,\n",
    "            self.y_test_scaled,\n",
    "            self.X_test,\n",
    "            self.y_test,\n",
    "            self.dates_train,\n",
    "            self.dates_test,\n",
    "            self.features_test_df\n",
    "        ) = self.preprocessor.preprocess_data(self.data)\n",
    "        print(self.X_train_scaled.shape)\n",
    "    \n",
    "    def reshape_for_lstm(self):\n",
    "        self.X_train_scaled = self.X_train_scaled.reshape((self.X_train_scaled.shape[0], self.X_train_scaled.shape[1], self.X_train_scaled.shape[2]))\n",
    "        self.X_test_scaled = self.X_test_scaled.reshape((self.X_test_scaled.shape[0], self.X_test_scaled.shape[1], self.X_test_scaled.shape[2]))\n",
    "\n",
    "    def build_model_lstm(self):\n",
    "        self.reshape_for_lstm()\n",
    "        timesteps = self.X_train_scaled.shape[1] \n",
    "        features = self.X_train_scaled.shape[2] \n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(timesteps, features)))\n",
    "        model.add(LSTM(517, return_sequences=False))\n",
    "        model.add(Dropout(0.4808067231743268)) # Dropout Regularization\n",
    "        # model.add(LSTM(120, return_sequences=False))\n",
    "        # model.add(Dropout(0.23702192322434543)) # Dropout Regularization\n",
    "        model.add(Dense(36, activation='relu'))\n",
    "        # model.add(BatchNormalization()) # Batch Normalization\n",
    "        # model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(1))  # No activation for regression\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss=self.loss, metrics=self.metrics)\n",
    "        model.summary()\n",
    "        self.model = model\n",
    "        save_and_visualize_model(self.model)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.history = self.model.fit(\n",
    "            self.X_train_scaled, \n",
    "            self.y_train_scaled, \n",
    "            epochs = self.epochs, \n",
    "            batch_size = self.batch_size, \n",
    "            validation_split = self.validation_split, \n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        plot_loss_training_history(self.history)\n",
    "        plot_mae_training_history(self.history)\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        self.evaluator = ModelEvaluator(self.model, self.X_test, self.y_test, self.X_test_scaled, self.y_test_scaled, self.y_scaler)\n",
    "        self.evaluator.evaluate_model()\n",
    "        # self.evaluator.atr_to_data()\n",
    "    \n",
    "    def predict_model(self):\n",
    "        self.predictions_inversed = self.evaluator.predict_model()\n",
    "        print(self.predictions_inversed.shape)\n",
    "\n",
    "    def save_model(self):  \n",
    "        self.model_path = f'{self.current_timestamp}_LSTM_model_epochs_{self.epochs}.keras'\n",
    "        self.model.save(self.model_path)\n",
    "        print(\"Model saved successfully.\")\n",
    "\n",
    "    def generate_model_signals(self):\n",
    "        self.X_test = generate_signal(self.features_test_df, self.predictions_inversed, self.dates_test)\n",
    "        # print(self.X_test)\n",
    "\n",
    "    def backtest_signals(self):\n",
    "        run_backtest(data=self.X_test, plot=self.plot)\n",
    "\n",
    "    def run_and_train(self):\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.build_model_lstm()\n",
    "        self.train_model()\n",
    "        self.plot_training_history()\n",
    "        self.evaluate_model()\n",
    "        self.predict_model()\n",
    "        self.save_model()\n",
    "        self.generate_model_signals()\n",
    "        self.backtest_signals()\n",
    "\n",
    "    def run_with_pretrained(self):\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.reshape_for_lstm()\n",
    "        self.evaluate_model()\n",
    "        self.predict_model()\n",
    "        self.generate_model_signals()\n",
    "        self.backtest_signals()\n",
    "\n",
    "\n",
    "model = LSTMModel(#model_path = 'backtests/Low_MAE/backtest_3/2024_07_08_01_38_10_LSTM_model_epochs_145.keras',\n",
    "                  #data_path='fear_greed_btc_combined.csv',\n",
    "                  test_size=0.25, \n",
    "                  learning_rate=0.0005514365217126862, \n",
    "                  epochs=145, \n",
    "                  batch_size=122, \n",
    "                  validation_split=0.25, \n",
    "                  plot=True)\n",
    "\n",
    "model.run_and_train()\n",
    "# model.run_with_pretrained()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fear_greed_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome! All code included in the Python Implementation is also included here for ease of use. You can run this entire notebook from start to finish, and look at generated console outputs, and visualizations generated as saved PNGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cell below gathers Fear and Index Data, and combines it with Bitcoin price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "!pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "def fetch_fear_and_greed_btc():\n",
    "    # Define the API endpoint and parameters for Fear and Greed Index\n",
    "    fng_api_url = \"https://api.alternative.me/fng/\"\n",
    "    fng_params = {\n",
    "        'limit': 0,  # Get all available data\n",
    "        'format': 'json'\n",
    "    }\n",
    "\n",
    "    # Make the GET request to the Fear and Greed Index API\n",
    "    response = requests.get(fng_api_url, params=fng_params)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        fng_data = response.json()\n",
    "        # Convert the data to a Pandas DataFrame\n",
    "        fng_df = pd.DataFrame(fng_data['data'])\n",
    "        # Ensure the timestamp column is of numeric type before converting to datetime\n",
    "        fng_df['timestamp'] = pd.to_numeric(fng_df['timestamp'], errors='coerce')\n",
    "        # Convert the timestamp column to datetime\n",
    "        fng_df['timestamp'] = pd.to_datetime(fng_df['timestamp'], unit='s')\n",
    "        # Drop the time_until_update column\n",
    "        fng_df.drop(columns=['time_until_update'], inplace=True)\n",
    "        # Set the timestamp as the index\n",
    "        fng_df.set_index('timestamp', inplace=True)\n",
    "        # Sort the DataFrame by the index (timestamp) in ascending order\n",
    "        fng_df.sort_index(inplace=True)\n",
    "        # Save the Fear and Greed Index DataFrame to a CSV file with timestamp as index and column name 'timestamp'\n",
    "        fng_df.to_csv('fear_and_greed_index.csv', index=True, index_label='timestamp')\n",
    "        print(\"Fear and Greed Index data has been saved to 'fear_and_greed_index.csv'.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch Fear and Greed Index data. Status code: {response.status_code}\")\n",
    "\n",
    "    # Fetch daily Bitcoin prices using Yahoo Finance\n",
    "    btc_data = yf.download('BTC-USD', start=fng_df.index.min().strftime('%Y-%m-%d'), end=fng_df.index.max().strftime('%Y-%m-%d'))\n",
    "\n",
    "    # Concatenate Fear and Greed Index DataFrame with Bitcoin DataFrame based on date index\n",
    "    combined_df = pd.concat([fng_df, btc_data], axis=1, join='inner')\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file\n",
    "    combined_df.to_csv('fear_greed_btc_combined.csv', index=True, index_label='timestamp')\n",
    "    print(\"Combined data has been saved to 'fear_greed_btc_combined.csv'.\")\n",
    "\n",
    "    return combined_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below contains a DataPreprocessor Class for getting data ready for use by our LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, X_scaler, y_scaler, lag_features=['value', 'Close'], lags=5, target_col='Close', test_size=.25):\n",
    "        self.lag_features = lag_features\n",
    "        self.lags = lags\n",
    "        self.target_col = target_col\n",
    "        self.test_size = test_size\n",
    "        self.X_scaler = X_scaler\n",
    "        self.y_scaler = y_scaler\n",
    "\n",
    "    def create_lagged_features(self, df):\n",
    "        for feature in self.lag_features:\n",
    "            for lag in range(1, self.lags + 1):\n",
    "                df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "        df['target'] = df[self.target_col].shift(-1)\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def normalize_data(self, X_train, X_test, y_train, y_test):\n",
    "        X_train_scaled = self.X_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.X_scaler.transform(X_test)\n",
    "        \n",
    "        y_train = y_train.values.reshape(-1, 1)\n",
    "        y_train_scaled = self.y_scaler.fit_transform(y_train)\n",
    "        y_test = y_test.values.reshape(-1, 1)\n",
    "        y_test_scaled = self.y_scaler.transform(y_test)\n",
    "\n",
    "        return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled\n",
    "\n",
    "    def split_train_test(self, data):\n",
    "        lagged_df = self.create_lagged_features(data)\n",
    "        X = lagged_df.drop(columns=['target', 'value_classification'])\n",
    "        y = lagged_df['target']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, shuffle=False)\n",
    "        \n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.normalize_data(\n",
    "            X_train, X_test, y_train, y_test\n",
    "        )\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, X_test, y_test\n",
    "\n",
    "    def preprocess_data(self, data):\n",
    "        return self.split_train_test(data)\n",
    "\n",
    "    def inverse_transform_y(self, y_scaled):\n",
    "        return self.y_scaler.inverse_transform(y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the Signal Generation function. Update the code here to implement a new strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import datetime\n",
    "\n",
    "def generate_signal(test_features, predictions, model_path=None):\n",
    "\n",
    "    # put your predictions vector back into the test features dataframe\n",
    "    test_features['predictions'] = predictions\n",
    "\n",
    "####################################################################################\n",
    "#------------------------CREATE YOUR STRATEGY HERE---------------------------------#\n",
    "####################################################################################\n",
    "\n",
    "    # Initialize an empty list to store signals\n",
    "    signals = []\n",
    "\n",
    "    # Iterate through each row of the DataFrame\n",
    "    for i in range(len(test_features)):\n",
    "        close_lag_1 = test_features['Close_lag_1'].iloc[i]\n",
    "        prediction = test_features['predictions'].iloc[i]\n",
    "        \n",
    "        # Define your buy and sell conditions here (modular and editable)\n",
    "        if close_lag_1 < prediction:\n",
    "            signal = 1  # Buy signal\n",
    "        else:\n",
    "            signal = -1  # Sell signal\n",
    "        \n",
    "        signals.append(signal)\n",
    "\n",
    "    # Add the signals list as a new column 'signal' in the DataFrame\n",
    "    test_features['Signal'] = signals\n",
    "\n",
    "    # Get the current timestamp and format it\n",
    "    current_timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    # Define the full path for the new CSV file\n",
    "    csv_path = os.path.join(f'{current_timestamp}_new_data_with_positions.csv')\n",
    "\n",
    "    # Save new_data with positions\n",
    "    test_features.to_csv(csv_path, index=True)\n",
    "\n",
    "    return test_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the ModelEvaluator Class, used for evaluating our model's predictive capabilities on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_signals import generate_signal\n",
    "from plotting_utils import plot_predicted_actual, plot_residuals\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def __init__(self, model, X_test, y_test, X_test_scaled, y_test_scaled, y_scaler, model_path=None):\n",
    "        self.model = model\n",
    "        self.model_path = model_path\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.X_test_scaled = X_test_scaled\n",
    "        self.y_test_scaled = y_test_scaled\n",
    "        self.y_scaler = y_scaler\n",
    "        self.predictions = None\n",
    "        self.predictions_inversed = None\n",
    "        self.y_test_inversed = None\n",
    "\n",
    "        if not self.model and model_path:\n",
    "            self.load_saved_model(model_path)    \n",
    "    \n",
    "    def load_saved_model(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "        print(f'Model loaded from {model_path}')\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        loss, mae = self.model.evaluate(self.X_test_scaled, self.y_test_scaled, verbose=2)\n",
    "        error_in_dollars = self.y_test.mean() * mae\n",
    "        print(f'Test Loss: {loss:.4f}')\n",
    "        print(f'Test MAE: {mae:.2f}')\n",
    "        print(f'MAE in dollars: +/- ${error_in_dollars:.2f}')\n",
    "\n",
    "    def atr_to_data(self, window=30):\n",
    "        self.X_test['ATR'] = self.calculate_atr()\n",
    "        atr_total_test = self.X_test['ATR'].mean()\n",
    "        atr_last_window = self.X_test['ATR'].iloc[-window:].mean()\n",
    "        print(f\"ATR for all test observations: ${atr_total_test:.2f}\")\n",
    "        print(f\"ATR for last {window} observations: ${atr_last_window:.2f}\")\n",
    "\n",
    "    def calculate_atr(self, window=14):\n",
    "        high_low = self.X_test['High'] - self.X_test['Low']\n",
    "        high_close_prev = abs(self.X_test['High'] - self.X_test['Close'].shift(1))\n",
    "        low_close_prev = abs(self.X_test['Low'] - self.X_test['Close'].shift(1))\n",
    "\n",
    "        tr = high_low.to_frame(name='HL')\n",
    "        tr['HC_prev'] = high_close_prev\n",
    "        tr['LC_prev'] = low_close_prev\n",
    "\n",
    "        true_range = tr.max(axis=1)\n",
    "\n",
    "        atr = true_range.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "        return atr\n",
    "        \n",
    "    def predict_model(self):\n",
    "        self.predictions = self.model.predict(self.X_test_scaled)\n",
    "        self.predictions_inversed = self.y_scaler.inverse_transform(self.predictions).flatten()\n",
    "        self.y_test_inversed = self.y_scaler.inverse_transform(self.y_test_scaled).flatten()\n",
    "        plot_predicted_actual(self.y_test_inversed, self.predictions_inversed)\n",
    "        plot_residuals(self.y_test_inversed, self.predictions_inversed)\n",
    "\n",
    "        return self.predictions_inversed\n",
    "\n",
    "    def generate_model_signals(self):\n",
    "        self.X_test = generate_signal(self.X_test_scaled, self.predictions_inversed)\n",
    "        print(self.X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the functions for generating the visualizations we will see when our LSTMModel trains and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "def plot_loss_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    save_plot(\"loss_training_history\")\n",
    "\n",
    "def plot_mae_training_history(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['mean_absolute_error'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')\n",
    "    plt.title('Model MAE Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    save_plot(\"MAE_training_history\")\n",
    "\n",
    "def plot_predicted_actual(actual, predicted):\n",
    "    df = pd.DataFrame({'Actual': actual, 'Predicted': predicted})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='Actual', y='Predicted', data=df)\n",
    "    plt.plot([min(actual), max(actual)], [min(actual), max(actual)], color='red', linestyle='--')\n",
    "    plt.title('Predicted vs. Actual Values')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.grid(True)\n",
    "    save_plot(\"Predicted_vs_Actual\")\n",
    "\n",
    "def plot_residuals(actual, predicted):\n",
    "    residuals = [actual - predicted for actual, predicted in zip(actual, predicted)]\n",
    "    df = pd.DataFrame({'Actual': actual, 'Predicted': predicted, 'Residuals': residuals})\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='Predicted', y='Residuals', data=df)\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.title('Residuals Plot')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.grid(True)\n",
    "    save_plot(\"Residuals\")\n",
    "\n",
    "def save_and_visualize_model(model, img_dir=None):\n",
    "    timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    if img_dir is None:\n",
    "        img_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    os.makedirs(img_dir, exist_ok=True)\n",
    "    img_path = os.path.join(img_dir, f\"model_{timestamp}.png\")\n",
    "    plot_model(\n",
    "        model,\n",
    "        to_file=img_path,\n",
    "        show_shapes=True,\n",
    "        show_dtype=False,\n",
    "        show_layer_names=True,\n",
    "        rankdir=\"TB\",\n",
    "        expand_nested=False,\n",
    "        dpi=200,\n",
    "        show_layer_activations=True,\n",
    "        show_trainable=True\n",
    "    )\n",
    "    print(f\"Model visualization saved and displayed from {img_path}\")\n",
    "    # save_plot(\"Model_Arc\")\n",
    "\n",
    "def plot_PCA(X_scaled):\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)  # Reduce to 2 dimensions\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Plot PCA results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "    plt.title('PCA Visualization')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.grid(True)\n",
    "    # plt.show()\n",
    "\n",
    "    save_plot(\"PCA_graph\")\n",
    "\n",
    "\n",
    "def save_plot(plot_name):\n",
    "    current_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    plt.savefig(f'{plot_name}_{current_timestamp}.png')\n",
    "    plt.close()\n",
    "    print(f\"{plot_name} plot saved as '{plot_name}_{current_timestamp}.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the Backtesting code so we can test the efficacy of our predictions and strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "!pip install backtesting\n",
    "from backtesting import Backtest, Strategy\n",
    "    \n",
    "class SignalStrategy(Strategy):\n",
    "    def init(self):\n",
    "        self.signal = self.data.Signal\n",
    "\n",
    "    def next(self):\n",
    "        current_signal = self.data.Signal[-1]\n",
    "        current_date = self.data.index[-1]\n",
    "        # print(f\"Date: {current_date}, Current position size: {self.position.size}, Signal: {current_signal}, Position: {self.position.is_long}\")\n",
    "        \n",
    "        if current_signal == 1:\n",
    "            # print(\"Executing BUY order\")\n",
    "            self.buy(size=1)\n",
    "        elif current_signal == -1 and self.position.is_long:\n",
    "            # print(\"Attempting to SELL entire position\")\n",
    "            try:\n",
    "                self.position.close()  # This closes the entire position\n",
    "                # print(\"SELL order executed - entire position closed\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing SELL order: {e}\")\n",
    "        elif current_signal == 0:\n",
    "            # print(\"No trade executed\")\n",
    "            pass\n",
    "    \n",
    "        \n",
    "        # print(f\"Current position size: {self.position.size}\")\n",
    "\n",
    "\n",
    "def run_backtest(data_path=None, data=None, plot=True, cash=1_000_000, commission=0.002, trade_on_close=True):\n",
    "    if data_path:\n",
    "        # Load and preprocess the data from the specified path\n",
    "        dataframe = pd.read_csv(data_path, index_col='Date', parse_dates=True)\n",
    "        dataframe = dataframe.sort_index()\n",
    "        dataframe = dataframe.dropna()\n",
    "        dataframe = dataframe.drop_duplicates()\n",
    "        dataframe.columns = [column.capitalize() for column in dataframe.columns]\n",
    "    elif data is not None:\n",
    "        # Use self.data if called from LSTMModel instance\n",
    "        dataframe = data  # Assuming `self.data` is defined in LSTMModel\n",
    "    \n",
    "    # Initialize and run the backtest\n",
    "    bt = Backtest(dataframe, SignalStrategy, cash=cash, commission=commission, trade_on_close=trade_on_close)\n",
    "    stats = bt.run()\n",
    "\n",
    "    # Print the statistics and plot the backtest results\n",
    "    print(stats)\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    stats_output_file = f'backtest_stats_{current_time}.txt'\n",
    "\n",
    "    # Save the statistics to a text file if stats_output_file is provided\n",
    "    with open(stats_output_file, 'w') as f:\n",
    "        f.write(str(stats))\n",
    "\n",
    "    if plot == True:\n",
    "        bt.plot()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main Brain of the code, the LSTMModel Class. This is where your entire model will use all the modules above to create, train and test an LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data path preloaded. Downloading Fear and Greed and BTC data...\n",
      "Fear and Greed Index data has been saved to 'fear_and_greed_index.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data has been saved to 'fear_greed_btc_combined.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,020</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m100,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m3,020\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,841</span> (405.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m103,841\u001b[0m (405.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,841</span> (405.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,841\u001b[0m (405.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Model visualization saved and displayed from /Users/joshbazz/Desktop/Bootcamp/fear-greed-lstm/model_2024_07_09_15_05_04.png\n",
      "Epoch 1/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1558 - mean_absolute_error: 0.2314 - val_loss: 0.0077 - val_mean_absolute_error: 0.0651\n",
      "Epoch 2/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0667 - val_loss: 0.0071 - val_mean_absolute_error: 0.0611\n",
      "Epoch 3/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mean_absolute_error: 0.0539 - val_loss: 0.0043 - val_mean_absolute_error: 0.0498\n",
      "Epoch 4/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - mean_absolute_error: 0.0521 - val_loss: 0.0057 - val_mean_absolute_error: 0.0590\n",
      "Epoch 5/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0056 - mean_absolute_error: 0.0459 - val_loss: 0.0045 - val_mean_absolute_error: 0.0516\n",
      "Epoch 6/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0058 - mean_absolute_error: 0.0453 - val_loss: 0.0072 - val_mean_absolute_error: 0.0636\n",
      "Epoch 7/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mean_absolute_error: 0.0473 - val_loss: 0.0056 - val_mean_absolute_error: 0.0565\n",
      "Epoch 8/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0061 - mean_absolute_error: 0.0454 - val_loss: 0.0053 - val_mean_absolute_error: 0.0550\n",
      "Epoch 9/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0062 - mean_absolute_error: 0.0444 - val_loss: 0.0036 - val_mean_absolute_error: 0.0449\n",
      "Epoch 10/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mean_absolute_error: 0.0388 - val_loss: 0.0046 - val_mean_absolute_error: 0.0505\n",
      "Epoch 11/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0422 - val_loss: 0.0064 - val_mean_absolute_error: 0.0599\n",
      "Epoch 12/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0405 - val_loss: 0.0056 - val_mean_absolute_error: 0.0560\n",
      "Epoch 13/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0412 - val_loss: 0.0042 - val_mean_absolute_error: 0.0508\n",
      "Epoch 14/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0402 - val_loss: 0.0094 - val_mean_absolute_error: 0.0836\n",
      "Epoch 15/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0061 - mean_absolute_error: 0.0439 - val_loss: 0.0045 - val_mean_absolute_error: 0.0533\n",
      "Epoch 16/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - mean_absolute_error: 0.0395 - val_loss: 0.0038 - val_mean_absolute_error: 0.0482\n",
      "Epoch 17/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mean_absolute_error: 0.0432 - val_loss: 0.0043 - val_mean_absolute_error: 0.0523\n",
      "Epoch 18/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040 - mean_absolute_error: 0.0375 - val_loss: 0.0077 - val_mean_absolute_error: 0.0737\n",
      "Epoch 19/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mean_absolute_error: 0.0436 - val_loss: 0.0052 - val_mean_absolute_error: 0.0586\n",
      "Epoch 20/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mean_absolute_error: 0.0349 - val_loss: 0.0064 - val_mean_absolute_error: 0.0611\n",
      "Epoch 21/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0381 - val_loss: 0.0042 - val_mean_absolute_error: 0.0510\n",
      "Epoch 22/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - mean_absolute_error: 0.0397 - val_loss: 0.0056 - val_mean_absolute_error: 0.0574\n",
      "Epoch 23/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0368 - val_loss: 0.0098 - val_mean_absolute_error: 0.0752\n",
      "Epoch 24/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0394 - val_loss: 0.0069 - val_mean_absolute_error: 0.0709\n",
      "Epoch 25/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0048 - mean_absolute_error: 0.0385 - val_loss: 0.0048 - val_mean_absolute_error: 0.0563\n",
      "Epoch 26/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mean_absolute_error: 0.0362 - val_loss: 0.0052 - val_mean_absolute_error: 0.0590\n",
      "Epoch 27/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mean_absolute_error: 0.0362 - val_loss: 0.0055 - val_mean_absolute_error: 0.0603\n",
      "Epoch 28/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0038 - mean_absolute_error: 0.0348 - val_loss: 0.0049 - val_mean_absolute_error: 0.0571\n",
      "Epoch 29/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0045 - mean_absolute_error: 0.0366 - val_loss: 0.0061 - val_mean_absolute_error: 0.0606\n",
      "Epoch 30/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0046 - mean_absolute_error: 0.0371 - val_loss: 0.0070 - val_mean_absolute_error: 0.0656\n",
      "Epoch 31/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0368 - val_loss: 0.0054 - val_mean_absolute_error: 0.0608\n",
      "Epoch 32/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0036 - mean_absolute_error: 0.0352 - val_loss: 0.0049 - val_mean_absolute_error: 0.0573\n",
      "Epoch 33/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mean_absolute_error: 0.0349 - val_loss: 0.0073 - val_mean_absolute_error: 0.0731\n",
      "Epoch 34/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0047 - mean_absolute_error: 0.0388 - val_loss: 0.0050 - val_mean_absolute_error: 0.0584\n",
      "Epoch 35/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mean_absolute_error: 0.0365 - val_loss: 0.0060 - val_mean_absolute_error: 0.0645\n",
      "Epoch 36/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0377 - val_loss: 0.0055 - val_mean_absolute_error: 0.0612\n",
      "Epoch 37/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mean_absolute_error: 0.0354 - val_loss: 0.0080 - val_mean_absolute_error: 0.0723\n",
      "Epoch 38/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0393 - val_loss: 0.0081 - val_mean_absolute_error: 0.0743\n",
      "Epoch 39/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - mean_absolute_error: 0.0360 - val_loss: 0.0054 - val_mean_absolute_error: 0.0608\n",
      "Epoch 40/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mean_absolute_error: 0.0362 - val_loss: 0.0077 - val_mean_absolute_error: 0.0748\n",
      "Epoch 41/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0359 - val_loss: 0.0062 - val_mean_absolute_error: 0.0656\n",
      "Epoch 42/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mean_absolute_error: 0.0347 - val_loss: 0.0059 - val_mean_absolute_error: 0.0642\n",
      "Epoch 43/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 - mean_absolute_error: 0.0386 - val_loss: 0.0083 - val_mean_absolute_error: 0.0748\n",
      "Epoch 44/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0366 - val_loss: 0.0064 - val_mean_absolute_error: 0.0674\n",
      "Epoch 45/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0034 - mean_absolute_error: 0.0333 - val_loss: 0.0069 - val_mean_absolute_error: 0.0692\n",
      "Epoch 46/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mean_absolute_error: 0.0363 - val_loss: 0.0066 - val_mean_absolute_error: 0.0680\n",
      "Epoch 47/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0040 - mean_absolute_error: 0.0359 - val_loss: 0.0074 - val_mean_absolute_error: 0.0726\n",
      "Epoch 48/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0037 - mean_absolute_error: 0.0334 - val_loss: 0.0072 - val_mean_absolute_error: 0.0715\n",
      "Epoch 49/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - mean_absolute_error: 0.0368 - val_loss: 0.0068 - val_mean_absolute_error: 0.0689\n",
      "Epoch 50/50\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0039 - mean_absolute_error: 0.0342 - val_loss: 0.0074 - val_mean_absolute_error: 0.0723\n",
      "loss_training_history plot saved as 'loss_training_history_2024_07_09_15_05_08.png'\n",
      "MAE_training_history plot saved as 'MAE_training_history_2024_07_09_15_05_08.png'\n",
      "19/19 - 0s - 892us/step - loss: 0.0077 - mean_absolute_error: 0.0699\n",
      "Test Loss: 0.0077\n",
      "Test MAE: 0.07\n",
      "MAE in dollars: +/- $2670.00\n",
      "ATR for all test observations: $1339.51\n",
      "ATR for last 30 observations: $1851.21\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Predicted_vs_Actual plot saved as 'Predicted_vs_Actual_2024_07_09_15_05_08.png'\n",
      "Residuals plot saved as 'Residuals_2024_07_09_15_05_08.png'\n",
      "Model saved successfully.\n",
      "Start                     2022-11-30 00:00:00\n",
      "End                       2024-07-07 00:00:00\n",
      "Duration                    585 days 00:00:00\n",
      "Exposure Time [%]                   69.453925\n",
      "Equity Final [$]               2023585.796727\n",
      "Equity Peak [$]                2059090.218031\n",
      "Return [%]                          102.35858\n",
      "Buy & Hold Return [%]              225.298619\n",
      "Return (Ann.) [%]                   55.121867\n",
      "Volatility (Ann.) [%]               49.903892\n",
      "Sharpe Ratio                          1.10456\n",
      "Sortino Ratio                        3.076273\n",
      "Calmar Ratio                         2.758984\n",
      "Max. Drawdown [%]                  -19.979043\n",
      "Avg. Drawdown [%]                   -3.729403\n",
      "Max. Drawdown Duration      240 days 00:00:00\n",
      "Avg. Drawdown Duration       21 days 00:00:00\n",
      "# Trades                                   93\n",
      "Win Rate [%]                        83.870968\n",
      "Best Trade [%]                     115.738432\n",
      "Worst Trade [%]                     -4.746436\n",
      "Avg. Trade [%]                      52.192161\n",
      "Max. Trade Duration         348 days 00:00:00\n",
      "Avg. Trade Duration         192 days 00:00:00\n",
      "Profit Factor                      165.413287\n",
      "Expectancy [%]                      60.271575\n",
      "SQN                                 12.950472\n",
      "_strategy                      SignalStrategy\n",
      "_equity_curve                             ...\n",
      "_trades                       Size  EntryB...\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%d %b'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%m/%Y'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:455: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df2 = (df.assign(_width=1).set_index('datetime')\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:659: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:659: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from plotting_utils import *\n",
    "from fetch_data import fetch_fear_and_greed_btc\n",
    "from generate_signals import generate_signal\n",
    "from backtester_utils import *\n",
    "from DataPreprocessor import DataPreprocessor\n",
    "from ModelEvaluator import ModelEvaluator\n",
    "\n",
    "\n",
    "class LSTMModel:\n",
    "    def __init__(self, model_path=None, data_path=None, lags=5, test_size=.25, learning_rate = 0.001, epochs=50, batch_size=32, validation_split=0.2, plot=True):\n",
    "        self.model = None\n",
    "        self.model_path = model_path\n",
    "        self.history = None\n",
    "        self.data_path = data_path\n",
    "        self.lag_features = ['value', 'Close'] # change these if you want to calculate lags on different feature columns\n",
    "        self.target_col = 'Close' # change this if you want to target a different variable than Close\n",
    "        self.X_scaler = RobustScaler()\n",
    "        self.y_scaler = RobustScaler()\n",
    "        self.preprocessor = DataPreprocessor(self.X_scaler, self.y_scaler, self.lag_features, lags, self.target_col, test_size)\n",
    "        self.current_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        self.learning_rate = learning_rate \n",
    "        self.loss = 'mean_squared_error' # change this if you're not going to solve for a regression target\n",
    "        self.metrics = ['mean_absolute_error']  # change this if you're not going to solve for a regression target\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "        self.plot = plot # set plot to false when instantiating if you dont want the backtest graph\n",
    "\n",
    "        if model_path:\n",
    "            self.load_saved_model(model_path)\n",
    "    \n",
    "    def load_saved_model(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "        print(f'Model loaded from {model_path}')\n",
    "\n",
    "    # Loads Data from a User-fed CSV Path, if CSV passed\n",
    "    def load_data(self):\n",
    "        if self.data_path is None:\n",
    "            print(\"No data path preloaded. Downloading Fear and Greed and BTC data...\")\n",
    "            self.data = fetch_fear_and_greed_btc()\n",
    "        else:\n",
    "            print(\"Data path preloaded. saving csv to dataframe...\")\n",
    "            self.data = pd.read_csv(self.data_path, parse_dates=True, index_col='timestamp') \n",
    "\n",
    "    def preprocess_data(self):\n",
    "        (\n",
    "            self.X_train_scaled,\n",
    "            self.X_test_scaled,\n",
    "            self.y_train_scaled,\n",
    "            self.y_test_scaled,\n",
    "            self.X_test,\n",
    "            self.y_test\n",
    "        ) = self.preprocessor.preprocess_data(self.data)\n",
    "\n",
    "    def reshape_for_lstm(self):\n",
    "        # Reshape from (samples, features) to (samples, 1, features)\n",
    "        self.X_train_scaled = self.X_train_scaled.reshape((self.X_train_scaled.shape[0], 1, self.X_train_scaled.shape[1])) \n",
    "        self.X_test_scaled = self.X_test_scaled.reshape((self.X_test_scaled.shape[0], 1, self.X_test_scaled.shape[1])) \n",
    "\n",
    "    def build_model_lstm(self):\n",
    "        self.reshape_for_lstm()\n",
    "        timesteps = self.X_train_scaled.shape[1] \n",
    "        features = self.X_train_scaled.shape[2] \n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(timesteps, features)))\n",
    "        model.add(LSTM(150, return_sequences=False))\n",
    "        model.add(Dropout(0.50)) # Dropout Regularization\n",
    "        model.add(Dense(20, activation='relu'))\n",
    "        model.add(Dense(1))  # No activation for regression\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss=self.loss, metrics=self.metrics)\n",
    "        model.summary()\n",
    "        self.model = model\n",
    "        save_and_visualize_model(self.model)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.history = self.model.fit(\n",
    "            self.X_train_scaled, \n",
    "            self.y_train_scaled, \n",
    "            epochs = self.epochs, \n",
    "            batch_size = self.batch_size, \n",
    "            validation_split = self.validation_split, \n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        plot_loss_training_history(self.history)\n",
    "        plot_mae_training_history(self.history)\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        self.evaluator = ModelEvaluator(self.model, self.X_test, self.y_test, self.X_test_scaled, self.y_test_scaled, self.y_scaler)\n",
    "        self.evaluator.evaluate_model()\n",
    "        self.evaluator.atr_to_data()\n",
    "    \n",
    "    def predict_model(self):\n",
    "        self.predictions_inversed = self.evaluator.predict_model()\n",
    "\n",
    "    def save_model(self):  \n",
    "        self.model_path = f'{self.current_timestamp}_LSTM_model_epochs_{self.epochs}.keras'\n",
    "        self.model.save(self.model_path)\n",
    "        print(\"Model saved successfully.\")\n",
    "\n",
    "    def generate_model_signals(self):\n",
    "        self.X_test = generate_signal(self.X_test, self.predictions_inversed)\n",
    "        # print(self.X_test)\n",
    "\n",
    "    def backtest_signals(self):\n",
    "        run_backtest(data=self.X_test, plot=self.plot)\n",
    "\n",
    "    def run_and_train(self):\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.build_model_lstm()\n",
    "        self.train_model()\n",
    "        self.plot_training_history()\n",
    "        self.evaluate_model()\n",
    "        self.predict_model()\n",
    "        self.save_model()\n",
    "        self.generate_model_signals()\n",
    "        self.backtest_signals()\n",
    "\n",
    "    def run_with_pretrained(self):\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.reshape_for_lstm()\n",
    "        self.evaluate_model()\n",
    "        self.predict_model()\n",
    "        self.generate_model_signals()\n",
    "        self.backtest_signals()\n",
    "\n",
    "\n",
    "model = LSTMModel(test_size=0.25, \n",
    "                  learning_rate=0.001, \n",
    "                  epochs=50, \n",
    "                  batch_size=32, \n",
    "                  validation_split=0.25, \n",
    "                  plot=True)\n",
    "\n",
    "model.run_and_train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the optimizer code. Run this to fine tune your model's hyper parameters and get better predicitve capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[I 2024-07-09 15:06:22,736] A new study created in memory with name: no-name-8071a92b-94bc-4536-a87b-a0e5dd688343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fear and Greed Index data has been saved to 'fear_and_greed_index.csv'.\n",
      "Combined data has been saved to 'fear_greed_btc_combined.csv'.\n",
      "X_train_scaled shape: (1755, 17)\n",
      "X_test_scaled shape: (586, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:06:27,315] Trial 0 finished with value: 0.2169150412082672 and parameters: {'LSTM Neurons_0': 48, 'Dropout Rate_0': 0.31450434557263884, 'Dense Neurons': 3, 'learning_rate': 0.0058929355495651}. Best is trial 0 with value: 0.2169150412082672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1751, 17)\n",
      "X_test_scaled shape: (584, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:06:31,155] Trial 1 finished with value: 0.6041640043258667 and parameters: {'LSTM Neurons_0': 18, 'Dropout Rate_0': 0.17374010260975647, 'Dense Neurons': 17, 'learning_rate': 0.04065530598174142}. Best is trial 0 with value: 0.2169150412082672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1746, 17)\n",
      "X_test_scaled shape: (583, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:06:35,962] Trial 2 finished with value: 0.15657788515090942 and parameters: {'LSTM Neurons_0': 89, 'Dropout Rate_0': 0.019938702566134076, 'Dense Neurons': 18, 'learning_rate': 0.0036280585091146107}. Best is trial 2 with value: 0.15657788515090942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1742, 17)\n",
      "X_test_scaled shape: (581, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:06:40,735] Trial 3 finished with value: 0.3412560820579529 and parameters: {'LSTM Neurons_0': 80, 'Dropout Rate_0': 0.40862339197291453, 'Dense Neurons': 46, 'learning_rate': 0.01112844695793177}. Best is trial 2 with value: 0.15657788515090942.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1737, 17)\n",
      "X_test_scaled shape: (580, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:06:45,251] Trial 4 finished with value: 0.06925120204687119 and parameters: {'LSTM Neurons_0': 68, 'Dropout Rate_0': 0.4922541129858857, 'Dense Neurons': 4, 'learning_rate': 0.00045031943945022005}. Best is trial 4 with value: 0.06925120204687119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1733, 17)\n",
      "X_test_scaled shape: (578, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:06:49,393] Trial 5 finished with value: 0.08490287512540817 and parameters: {'LSTM Neurons_0': 55, 'Dropout Rate_0': 0.03368772365666216, 'Dense Neurons': 5, 'learning_rate': 0.001711552612433156}. Best is trial 4 with value: 0.06925120204687119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1728, 17)\n",
      "X_test_scaled shape: (577, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:06:53,263] Trial 6 finished with value: 0.0703185647726059 and parameters: {'LSTM Neurons_0': 21, 'Dropout Rate_0': 0.008733710203582785, 'Dense Neurons': 38, 'learning_rate': 0.00020994486102406156}. Best is trial 4 with value: 0.06925120204687119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1724, 17)\n",
      "X_test_scaled shape: (575, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:06:56,863] Trial 7 finished with value: 0.4097180962562561 and parameters: {'LSTM Neurons_0': 15, 'Dropout Rate_0': 0.31472047672445497, 'Dense Neurons': 12, 'learning_rate': 0.027112566864195848}. Best is trial 4 with value: 0.06925120204687119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1719, 17)\n",
      "X_test_scaled shape: (574, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:07:01,044] Trial 8 finished with value: 0.45466476678848267 and parameters: {'LSTM Neurons_0': 57, 'Dropout Rate_0': 0.29107903603258334, 'Dense Neurons': 47, 'learning_rate': 0.027726888159204294}. Best is trial 4 with value: 0.06925120204687119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (1715, 17)\n",
      "X_test_scaled shape: (572, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-09 15:07:05,653] Trial 9 finished with value: 0.09934979677200317 and parameters: {'LSTM Neurons_0': 68, 'Dropout Rate_0': 0.08680751374139938, 'Dense Neurons': 50, 'learning_rate': 0.0010866993731554748}. Best is trial 4 with value: 0.06925120204687119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 10\n",
      "Best trial:\n",
      "  Value: 0.06925120204687119\n",
      "  Params: \n",
      "    LSTM Neurons_0: 68\n",
      "    Dropout Rate_0: 0.4922541129858857\n",
      "    Dense Neurons: 4\n",
      "    learning_rate: 0.00045031943945022005\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from keras.backend import clear_session\n",
    "from keras.layers import Input, LSTM, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from fetch_data import fetch_fear_and_greed_btc\n",
    "from DataPreprocessor import DataPreprocessor\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "data = fetch_fear_and_greed_btc()\n",
    "X_scaler = RobustScaler()\n",
    "y_scaler = RobustScaler()\n",
    "preprocessor = DataPreprocessor(X_scaler, y_scaler)\n",
    "\n",
    "BATCHSIZE = 64\n",
    "VALIDATION_SPLIT = 0.25\n",
    "CLASSES = 10\n",
    "EPOCHS = 100\n",
    "\n",
    "def objective(trial):\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "\n",
    "    X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, _, _ = preprocessor.preprocess_data(data)\n",
    "\n",
    "    # Print shapes for debugging\n",
    "    print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "    print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1])) \n",
    "    X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "    timesteps = X_train_scaled.shape[1] \n",
    "    features = X_train_scaled.shape[2]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(timesteps, features)))\n",
    "    model.add(LSTM(units=trial.suggest_int('LSTM Neurons_0', 10, 100), return_sequences=True))\n",
    "    model.add(Dropout(trial.suggest_float('Dropout Rate_0', .0001, .50)))\n",
    "    # model.add(LSTM(units=trial.suggest_int('LSTM Neurons_1', 10, 1000), return_sequences=False))\n",
    "    # model.add(Dropout(trial.suggest_float('Dropout Rate_1 ', .0001, .50)))\n",
    "    model.add(Dense(trial.suggest_int('Dense Neurons', 1, 50), activation='relu'))\n",
    "    model.add(Dense(1))  # No activation for regression\n",
    "\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=['mean_absolute_error']\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train_scaled,\n",
    "        # validation_data=(X_test_scaled, y_test_scaled),\n",
    "        shuffle=False,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCHSIZE,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=10, timeout=100_000)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is another instance of the LSTMModel Class, using example optimization parameters above. You can change this as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data path preloaded. Downloading Fear and Greed and BTC data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fear and Greed Index data has been saved to 'fear_and_greed_index.csv'.\n",
      "Combined data has been saved to 'fear_greed_btc_combined.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,392</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">276</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │        \u001b[38;5;34m23,392\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m276\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,673</span> (92.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,673\u001b[0m (92.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,673</span> (92.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,673\u001b[0m (92.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Model visualization saved and displayed from /Users/joshbazz/Desktop/Bootcamp/fear-greed-lstm/model_2024_07_09_15_10_11.png\n",
      "Epoch 1/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3113 - mean_absolute_error: 0.3287 - val_loss: 0.9695 - val_mean_absolute_error: 0.8648\n",
      "Epoch 2/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2606 - mean_absolute_error: 0.3084 - val_loss: 0.6299 - val_mean_absolute_error: 0.7087\n",
      "Epoch 3/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1698 - mean_absolute_error: 0.2768 - val_loss: 0.3618 - val_mean_absolute_error: 0.5441\n",
      "Epoch 4/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1001 - mean_absolute_error: 0.2304 - val_loss: 0.1921 - val_mean_absolute_error: 0.3993\n",
      "Epoch 5/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0524 - mean_absolute_error: 0.1766 - val_loss: 0.1013 - val_mean_absolute_error: 0.2878\n",
      "Epoch 6/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0326 - mean_absolute_error: 0.1406 - val_loss: 0.0528 - val_mean_absolute_error: 0.2032\n",
      "Epoch 7/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0243 - mean_absolute_error: 0.1171 - val_loss: 0.0349 - val_mean_absolute_error: 0.1626\n",
      "Epoch 8/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0185 - mean_absolute_error: 0.0944 - val_loss: 0.0233 - val_mean_absolute_error: 0.1301\n",
      "Epoch 9/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0175 - mean_absolute_error: 0.0863 - val_loss: 0.0164 - val_mean_absolute_error: 0.1067\n",
      "Epoch 10/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0151 - mean_absolute_error: 0.0809 - val_loss: 0.0136 - val_mean_absolute_error: 0.0955\n",
      "Epoch 11/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mean_absolute_error: 0.0794 - val_loss: 0.0128 - val_mean_absolute_error: 0.0917\n",
      "Epoch 12/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0149 - mean_absolute_error: 0.0768 - val_loss: 0.0094 - val_mean_absolute_error: 0.0765\n",
      "Epoch 13/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mean_absolute_error: 0.0727 - val_loss: 0.0088 - val_mean_absolute_error: 0.0729\n",
      "Epoch 14/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0172 - mean_absolute_error: 0.0801 - val_loss: 0.0085 - val_mean_absolute_error: 0.0711\n",
      "Epoch 15/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - mean_absolute_error: 0.0750 - val_loss: 0.0078 - val_mean_absolute_error: 0.0674\n",
      "Epoch 16/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - mean_absolute_error: 0.0773 - val_loss: 0.0088 - val_mean_absolute_error: 0.0718\n",
      "Epoch 17/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mean_absolute_error: 0.0746 - val_loss: 0.0072 - val_mean_absolute_error: 0.0637\n",
      "Epoch 18/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - mean_absolute_error: 0.0678 - val_loss: 0.0063 - val_mean_absolute_error: 0.0587\n",
      "Epoch 19/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0116 - mean_absolute_error: 0.0712 - val_loss: 0.0074 - val_mean_absolute_error: 0.0637\n",
      "Epoch 20/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - mean_absolute_error: 0.0717 - val_loss: 0.0069 - val_mean_absolute_error: 0.0612\n",
      "Epoch 21/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - mean_absolute_error: 0.0705 - val_loss: 0.0072 - val_mean_absolute_error: 0.0625\n",
      "Epoch 22/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mean_absolute_error: 0.0706 - val_loss: 0.0092 - val_mean_absolute_error: 0.0712\n",
      "Epoch 23/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0124 - mean_absolute_error: 0.0702 - val_loss: 0.0080 - val_mean_absolute_error: 0.0663\n",
      "Epoch 24/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mean_absolute_error: 0.0693 - val_loss: 0.0069 - val_mean_absolute_error: 0.0611\n",
      "Epoch 25/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0105 - mean_absolute_error: 0.0672 - val_loss: 0.0060 - val_mean_absolute_error: 0.0571\n",
      "Epoch 26/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0120 - mean_absolute_error: 0.0676 - val_loss: 0.0065 - val_mean_absolute_error: 0.0594\n",
      "Epoch 27/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0119 - mean_absolute_error: 0.0661 - val_loss: 0.0061 - val_mean_absolute_error: 0.0580\n",
      "Epoch 28/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - mean_absolute_error: 0.0630 - val_loss: 0.0058 - val_mean_absolute_error: 0.0574\n",
      "Epoch 29/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - mean_absolute_error: 0.0622 - val_loss: 0.0069 - val_mean_absolute_error: 0.0621\n",
      "Epoch 30/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - mean_absolute_error: 0.0651 - val_loss: 0.0066 - val_mean_absolute_error: 0.0609\n",
      "Epoch 31/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - mean_absolute_error: 0.0664 - val_loss: 0.0065 - val_mean_absolute_error: 0.0613\n",
      "Epoch 32/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mean_absolute_error: 0.0650 - val_loss: 0.0060 - val_mean_absolute_error: 0.0593\n",
      "Epoch 33/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0620 - val_loss: 0.0062 - val_mean_absolute_error: 0.0598\n",
      "Epoch 34/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - mean_absolute_error: 0.0630 - val_loss: 0.0061 - val_mean_absolute_error: 0.0596\n",
      "Epoch 35/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mean_absolute_error: 0.0585 - val_loss: 0.0067 - val_mean_absolute_error: 0.0625\n",
      "Epoch 36/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mean_absolute_error: 0.0587 - val_loss: 0.0058 - val_mean_absolute_error: 0.0590\n",
      "Epoch 37/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - mean_absolute_error: 0.0577 - val_loss: 0.0056 - val_mean_absolute_error: 0.0588\n",
      "Epoch 38/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mean_absolute_error: 0.0567 - val_loss: 0.0052 - val_mean_absolute_error: 0.0569\n",
      "Epoch 39/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - mean_absolute_error: 0.0608 - val_loss: 0.0060 - val_mean_absolute_error: 0.0600\n",
      "Epoch 40/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - mean_absolute_error: 0.0609 - val_loss: 0.0057 - val_mean_absolute_error: 0.0586\n",
      "Epoch 41/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - mean_absolute_error: 0.0640 - val_loss: 0.0054 - val_mean_absolute_error: 0.0573\n",
      "Epoch 42/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0610 - val_loss: 0.0059 - val_mean_absolute_error: 0.0597\n",
      "Epoch 43/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mean_absolute_error: 0.0567 - val_loss: 0.0081 - val_mean_absolute_error: 0.0693\n",
      "Epoch 44/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mean_absolute_error: 0.0567 - val_loss: 0.0067 - val_mean_absolute_error: 0.0647\n",
      "Epoch 45/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mean_absolute_error: 0.0559 - val_loss: 0.0062 - val_mean_absolute_error: 0.0633\n",
      "Epoch 46/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mean_absolute_error: 0.0575 - val_loss: 0.0063 - val_mean_absolute_error: 0.0633\n",
      "Epoch 47/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mean_absolute_error: 0.0538 - val_loss: 0.0059 - val_mean_absolute_error: 0.0622\n",
      "Epoch 48/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - mean_absolute_error: 0.0567 - val_loss: 0.0061 - val_mean_absolute_error: 0.0624\n",
      "Epoch 49/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mean_absolute_error: 0.0577 - val_loss: 0.0061 - val_mean_absolute_error: 0.0624\n",
      "Epoch 50/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - mean_absolute_error: 0.0575 - val_loss: 0.0061 - val_mean_absolute_error: 0.0628\n",
      "Epoch 51/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mean_absolute_error: 0.0563 - val_loss: 0.0058 - val_mean_absolute_error: 0.0612\n",
      "Epoch 52/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mean_absolute_error: 0.0504 - val_loss: 0.0057 - val_mean_absolute_error: 0.0611\n",
      "Epoch 53/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mean_absolute_error: 0.0515 - val_loss: 0.0055 - val_mean_absolute_error: 0.0606\n",
      "Epoch 54/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - mean_absolute_error: 0.0559 - val_loss: 0.0058 - val_mean_absolute_error: 0.0612\n",
      "Epoch 55/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mean_absolute_error: 0.0548 - val_loss: 0.0057 - val_mean_absolute_error: 0.0614\n",
      "Epoch 56/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mean_absolute_error: 0.0549 - val_loss: 0.0064 - val_mean_absolute_error: 0.0643\n",
      "Epoch 57/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mean_absolute_error: 0.0562 - val_loss: 0.0057 - val_mean_absolute_error: 0.0617\n",
      "Epoch 58/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - mean_absolute_error: 0.0536 - val_loss: 0.0062 - val_mean_absolute_error: 0.0634\n",
      "Epoch 59/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - mean_absolute_error: 0.0516 - val_loss: 0.0061 - val_mean_absolute_error: 0.0629\n",
      "Epoch 60/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mean_absolute_error: 0.0536 - val_loss: 0.0059 - val_mean_absolute_error: 0.0621\n",
      "Epoch 61/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mean_absolute_error: 0.0530 - val_loss: 0.0067 - val_mean_absolute_error: 0.0652\n",
      "Epoch 62/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mean_absolute_error: 0.0535 - val_loss: 0.0062 - val_mean_absolute_error: 0.0633\n",
      "Epoch 63/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - mean_absolute_error: 0.0514 - val_loss: 0.0060 - val_mean_absolute_error: 0.0629\n",
      "Epoch 64/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mean_absolute_error: 0.0492 - val_loss: 0.0061 - val_mean_absolute_error: 0.0631\n",
      "Epoch 65/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mean_absolute_error: 0.0513 - val_loss: 0.0065 - val_mean_absolute_error: 0.0647\n",
      "Epoch 66/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mean_absolute_error: 0.0484 - val_loss: 0.0066 - val_mean_absolute_error: 0.0657\n",
      "Epoch 67/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mean_absolute_error: 0.0533 - val_loss: 0.0064 - val_mean_absolute_error: 0.0648\n",
      "Epoch 68/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mean_absolute_error: 0.0516 - val_loss: 0.0061 - val_mean_absolute_error: 0.0639\n",
      "Epoch 69/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mean_absolute_error: 0.0511 - val_loss: 0.0069 - val_mean_absolute_error: 0.0673\n",
      "Epoch 70/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mean_absolute_error: 0.0493 - val_loss: 0.0060 - val_mean_absolute_error: 0.0640\n",
      "Epoch 71/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mean_absolute_error: 0.0537 - val_loss: 0.0068 - val_mean_absolute_error: 0.0665\n",
      "Epoch 72/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mean_absolute_error: 0.0531 - val_loss: 0.0060 - val_mean_absolute_error: 0.0632\n",
      "Epoch 73/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mean_absolute_error: 0.0513 - val_loss: 0.0065 - val_mean_absolute_error: 0.0655\n",
      "Epoch 74/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - mean_absolute_error: 0.0493 - val_loss: 0.0060 - val_mean_absolute_error: 0.0630\n",
      "Epoch 75/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mean_absolute_error: 0.0493 - val_loss: 0.0060 - val_mean_absolute_error: 0.0634\n",
      "Epoch 76/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mean_absolute_error: 0.0495 - val_loss: 0.0063 - val_mean_absolute_error: 0.0647\n",
      "Epoch 77/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mean_absolute_error: 0.0487 - val_loss: 0.0061 - val_mean_absolute_error: 0.0640\n",
      "Epoch 78/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mean_absolute_error: 0.0519 - val_loss: 0.0058 - val_mean_absolute_error: 0.0628\n",
      "Epoch 79/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - mean_absolute_error: 0.0543 - val_loss: 0.0057 - val_mean_absolute_error: 0.0612\n",
      "Epoch 80/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mean_absolute_error: 0.0500 - val_loss: 0.0061 - val_mean_absolute_error: 0.0629\n",
      "Epoch 81/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - mean_absolute_error: 0.0529 - val_loss: 0.0058 - val_mean_absolute_error: 0.0625\n",
      "Epoch 82/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mean_absolute_error: 0.0522 - val_loss: 0.0064 - val_mean_absolute_error: 0.0659\n",
      "Epoch 83/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mean_absolute_error: 0.0505 - val_loss: 0.0061 - val_mean_absolute_error: 0.0645\n",
      "Epoch 84/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mean_absolute_error: 0.0508 - val_loss: 0.0073 - val_mean_absolute_error: 0.0696\n",
      "Epoch 85/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mean_absolute_error: 0.0520 - val_loss: 0.0058 - val_mean_absolute_error: 0.0631\n",
      "Epoch 86/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mean_absolute_error: 0.0498 - val_loss: 0.0064 - val_mean_absolute_error: 0.0668\n",
      "Epoch 87/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mean_absolute_error: 0.0521 - val_loss: 0.0066 - val_mean_absolute_error: 0.0666\n",
      "Epoch 88/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0063 - mean_absolute_error: 0.0491 - val_loss: 0.0064 - val_mean_absolute_error: 0.0653\n",
      "Epoch 89/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mean_absolute_error: 0.0501 - val_loss: 0.0065 - val_mean_absolute_error: 0.0664\n",
      "Epoch 90/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - mean_absolute_error: 0.0513 - val_loss: 0.0066 - val_mean_absolute_error: 0.0672\n",
      "Epoch 91/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054 - mean_absolute_error: 0.0457 - val_loss: 0.0067 - val_mean_absolute_error: 0.0674\n",
      "Epoch 92/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mean_absolute_error: 0.0517 - val_loss: 0.0070 - val_mean_absolute_error: 0.0691\n",
      "Epoch 93/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mean_absolute_error: 0.0494 - val_loss: 0.0069 - val_mean_absolute_error: 0.0685\n",
      "Epoch 94/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mean_absolute_error: 0.0468 - val_loss: 0.0075 - val_mean_absolute_error: 0.0715\n",
      "Epoch 95/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mean_absolute_error: 0.0455 - val_loss: 0.0070 - val_mean_absolute_error: 0.0697\n",
      "Epoch 96/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mean_absolute_error: 0.0499 - val_loss: 0.0070 - val_mean_absolute_error: 0.0697\n",
      "Epoch 97/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mean_absolute_error: 0.0468 - val_loss: 0.0070 - val_mean_absolute_error: 0.0694\n",
      "Epoch 98/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mean_absolute_error: 0.0481 - val_loss: 0.0069 - val_mean_absolute_error: 0.0691\n",
      "Epoch 99/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - mean_absolute_error: 0.0484 - val_loss: 0.0076 - val_mean_absolute_error: 0.0716\n",
      "Epoch 100/100\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mean_absolute_error: 0.0497 - val_loss: 0.0072 - val_mean_absolute_error: 0.0708\n",
      "loss_training_history plot saved as 'loss_training_history_2024_07_09_15_10_15.png'\n",
      "MAE_training_history plot saved as 'MAE_training_history_2024_07_09_15_10_16.png'\n",
      "19/19 - 0s - 759us/step - loss: 0.0076 - mean_absolute_error: 0.0682\n",
      "Test Loss: 0.0076\n",
      "Test MAE: 0.07\n",
      "MAE in dollars: +/- $2604.65\n",
      "ATR for all test observations: $1339.51\n",
      "ATR for last 30 observations: $1851.21\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Predicted_vs_Actual plot saved as 'Predicted_vs_Actual_2024_07_09_15_10_16.png'\n",
      "Residuals plot saved as 'Residuals_2024_07_09_15_10_16.png'\n",
      "Model saved successfully.\n",
      "Start                     2022-11-30 00:00:00\n",
      "End                       2024-07-07 00:00:00\n",
      "Duration                    585 days 00:00:00\n",
      "Exposure Time [%]                   72.525597\n",
      "Equity Final [$]               2217633.241871\n",
      "Equity Peak [$]                2220191.350465\n",
      "Return [%]                         121.763324\n",
      "Buy & Hold Return [%]              225.298619\n",
      "Return (Ann.) [%]                   64.226508\n",
      "Volatility (Ann.) [%]               50.055713\n",
      "Sharpe Ratio                           1.2831\n",
      "Sortino Ratio                        3.932089\n",
      "Calmar Ratio                         3.206743\n",
      "Max. Drawdown [%]                  -20.028578\n",
      "Avg. Drawdown [%]                   -3.039657\n",
      "Max. Drawdown Duration      109 days 00:00:00\n",
      "Avg. Drawdown Duration       17 days 00:00:00\n",
      "# Trades                                  168\n",
      "Win Rate [%]                        85.119048\n",
      "Best Trade [%]                      74.973904\n",
      "Worst Trade [%]                     -5.096245\n",
      "Avg. Trade [%]                      30.828811\n",
      "Max. Trade Duration         205 days 00:00:00\n",
      "Avg. Trade Duration          99 days 00:00:00\n",
      "Profit Factor                       99.640767\n",
      "Expectancy [%]                      33.349804\n",
      "SQN                                 19.791067\n",
      "_strategy                      SignalStrategy\n",
      "_equity_curve                             ...\n",
      "_trades                        Size  Entry...\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%d %b'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%m/%Y'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:455: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df2 = (df.assign(_width=1).set_index('datetime')\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:659: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/opt/anaconda3/envs/fear_greed_lstm/lib/python3.10/site-packages/backtesting/_plotting.py:659: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from plotting_utils import *\n",
    "from fetch_data import fetch_fear_and_greed_btc\n",
    "from generate_signals import generate_signal\n",
    "from backtester_utils import *\n",
    "from DataPreprocessor import DataPreprocessor\n",
    "from ModelEvaluator import ModelEvaluator\n",
    "\n",
    "\n",
    "class LSTMModel:\n",
    "    def __init__(self, model_path=None, data_path=None, lags=5, test_size=.25, learning_rate = 0.001, epochs=50, batch_size=32, validation_split=0.2, plot=True):\n",
    "        self.model = None\n",
    "        self.model_path = model_path\n",
    "        self.history = None\n",
    "        self.data_path = data_path\n",
    "        self.lag_features = ['value', 'Close'] # change these if you want to calculate lags on different feature columns\n",
    "        self.target_col = 'Close' # change this if you want to target a different variable than Close\n",
    "        self.X_scaler = RobustScaler()\n",
    "        self.y_scaler = RobustScaler()\n",
    "        self.preprocessor = DataPreprocessor(self.X_scaler, self.y_scaler, self.lag_features, lags, self.target_col, test_size)\n",
    "        self.current_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        self.learning_rate = learning_rate \n",
    "        self.loss = 'mean_squared_error' # change this if you're not going to solve for a regression target\n",
    "        self.metrics = ['mean_absolute_error']  # change this if you're not going to solve for a regression target\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "\n",
    "        self.plot = plot # set plot to false when instantiating if you dont want the backtest graph\n",
    "\n",
    "        if model_path:\n",
    "            self.load_saved_model(model_path)\n",
    "    \n",
    "    def load_saved_model(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "        print(f'Model loaded from {model_path}')\n",
    "\n",
    "    # Loads Data from a User-fed CSV Path, if CSV passed\n",
    "    def load_data(self):\n",
    "        if self.data_path is None:\n",
    "            print(\"No data path preloaded. Downloading Fear and Greed and BTC data...\")\n",
    "            self.data = fetch_fear_and_greed_btc()\n",
    "        else:\n",
    "            print(\"Data path preloaded. saving csv to dataframe...\")\n",
    "            self.data = pd.read_csv(self.data_path, parse_dates=True, index_col='timestamp') \n",
    "\n",
    "    def preprocess_data(self):\n",
    "        (\n",
    "            self.X_train_scaled,\n",
    "            self.X_test_scaled,\n",
    "            self.y_train_scaled,\n",
    "            self.y_test_scaled,\n",
    "            self.X_test,\n",
    "            self.y_test\n",
    "        ) = self.preprocessor.preprocess_data(self.data)\n",
    "\n",
    "    def reshape_for_lstm(self):\n",
    "        # Reshape from (samples, features) to (samples, 1, features)\n",
    "        self.X_train_scaled = self.X_train_scaled.reshape((self.X_train_scaled.shape[0], 1, self.X_train_scaled.shape[1])) \n",
    "        self.X_test_scaled = self.X_test_scaled.reshape((self.X_test_scaled.shape[0], 1, self.X_test_scaled.shape[1])) \n",
    "\n",
    "    def build_model_lstm(self):\n",
    "        self.reshape_for_lstm()\n",
    "        timesteps = self.X_train_scaled.shape[1] \n",
    "        features = self.X_train_scaled.shape[2] \n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(timesteps, features)))\n",
    "        model.add(LSTM(68, return_sequences=False))\n",
    "        model.add(Dropout(0.4922541129858857)) # Dropout Regularization\n",
    "        model.add(Dense(4, activation='relu'))\n",
    "        model.add(Dense(1))  # No activation for regression\n",
    "        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss=self.loss, metrics=self.metrics)\n",
    "        model.summary()\n",
    "        self.model = model\n",
    "        save_and_visualize_model(self.model)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.history = self.model.fit(\n",
    "            self.X_train_scaled, \n",
    "            self.y_train_scaled, \n",
    "            epochs = self.epochs, \n",
    "            batch_size = self.batch_size, \n",
    "            validation_split = self.validation_split, \n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        plot_loss_training_history(self.history)\n",
    "        plot_mae_training_history(self.history)\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        self.evaluator = ModelEvaluator(self.model, self.X_test, self.y_test, self.X_test_scaled, self.y_test_scaled, self.y_scaler)\n",
    "        self.evaluator.evaluate_model()\n",
    "        self.evaluator.atr_to_data()\n",
    "    \n",
    "    def predict_model(self):\n",
    "        self.predictions_inversed = self.evaluator.predict_model()\n",
    "\n",
    "    def save_model(self):  \n",
    "        self.model_path = f'{self.current_timestamp}_LSTM_model_epochs_{self.epochs}.keras'\n",
    "        self.model.save(self.model_path)\n",
    "        print(\"Model saved successfully.\")\n",
    "\n",
    "    def generate_model_signals(self):\n",
    "        self.X_test = generate_signal(self.X_test, self.predictions_inversed)\n",
    "\n",
    "    def backtest_signals(self):\n",
    "        run_backtest(data=self.X_test, plot=self.plot)\n",
    "\n",
    "    def run_and_train(self):\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.build_model_lstm()\n",
    "        self.train_model()\n",
    "        self.plot_training_history()\n",
    "        self.evaluate_model()\n",
    "        self.predict_model()\n",
    "        self.save_model()\n",
    "        self.generate_model_signals()\n",
    "        self.backtest_signals()\n",
    "\n",
    "    def run_with_pretrained(self):\n",
    "        self.load_data()\n",
    "        self.preprocess_data()\n",
    "        self.reshape_for_lstm()\n",
    "        self.evaluate_model()\n",
    "        self.predict_model()\n",
    "        self.generate_model_signals()\n",
    "        self.backtest_signals()\n",
    "\n",
    "\n",
    "model = LSTMModel(test_size=0.25, \n",
    "                  learning_rate=0.00045031943945022005, \n",
    "                  epochs=100, \n",
    "                  batch_size=100, \n",
    "                  validation_split=0.25, \n",
    "                  plot=True)\n",
    "\n",
    "model.run_and_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fear_greed_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
